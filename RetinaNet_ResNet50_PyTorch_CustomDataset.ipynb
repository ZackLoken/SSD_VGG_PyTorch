{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Reading and Cleaning Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion(); # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load annotation data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading JSON as dictionary\n",
    "def read_json(filename: str) -> dict:\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Reading {filename} file encountered an error: {e}\")\n",
    "    return data\n",
    "\n",
    "# Function to create a DataFrame from a list of records\n",
    "def create_dataframe(data: list) -> pd.DataFrame:\n",
    "    # Normalize the column levels and create a DataFrame\n",
    "    return pd.json_normalize(data)\n",
    "\n",
    "# Main function to iterate over files in directory and add to df\n",
    "def main():\n",
    "    # Assign directory and empty list for collecting records\n",
    "    directory = \"C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Annotations/\"  # annotation directory\n",
    "    records = []\n",
    "    \n",
    "    # Iterate over files in directory\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            # Read the JSON file as python dictionary \n",
    "            data = read_json(filename=f)\n",
    "        \n",
    "            # Create the dataframe for the array items in annotations key \n",
    "            df = create_dataframe(data=data['annotations'])\n",
    "            df.insert(loc=0, column='img_name', value=f'{f[-30:-5]}.JPG')\n",
    "        \n",
    "            df.rename(columns={\n",
    "                \"img_name\": \"img_name\",\n",
    "                \"name\": \"label\",\n",
    "                \"bounding_box.h\": \"bbox_height\",\n",
    "                \"bounding_box.w\": \"bbox_width\",\n",
    "                \"bounding_box.x\": \"bbox_x_topLeft\",\n",
    "                \"bounding_box.y\": \"bbox_y_topLeft\",\n",
    "                \"polygon.paths\": \"polygon_path\"\n",
    "            }, inplace=True)\n",
    "            \n",
    "            # Append the records to the list\n",
    "            records.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping non-file: {filename}\")\n",
    "\n",
    "    # Concatenate all records into a single DataFrame\n",
    "    annos_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "    # Convert x, y, h, w to xmin, ymin, xmax, ymax\n",
    "    annos_df['xmin'] = annos_df['bbox_x_topLeft']\n",
    "    annos_df['ymin'] = annos_df['bbox_y_topLeft']\n",
    "    annos_df['xmax'] = annos_df['bbox_x_topLeft'] + annos_df['bbox_width']\n",
    "    annos_df['ymax'] = annos_df['bbox_y_topLeft'] + annos_df['bbox_height']\n",
    "  \n",
    "    # Drop unnecessary columns \n",
    "    annos_df = annos_df.drop(columns=['bbox_height', 'bbox_width', 'bbox_x_topLeft', \n",
    "                                      'bbox_y_topLeft', 'id', 'slot_names', 'polygon_path'])\n",
    "        \n",
    "    return annos_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-process annotation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique image names\n",
    "unique_img_names = df['img_name'].unique()\n",
    "\n",
    "invalid_img_names = []\n",
    "for img_name in unique_img_names:\n",
    "    img_path = f'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Images/{img_name}'\n",
    "    img = Image.open(img_path)\n",
    "    if img.size == (5184, 3888):\n",
    "        invalid_img_names.append(img_name)\n",
    "\n",
    "# remove from df\n",
    "df = df[~df['img_name'].isin(invalid_img_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify classes with fewer than 200 occurrences as negative classes\n",
    "class_counts = df['label'].value_counts()\n",
    "negative_classes = class_counts[class_counts < 200].index.tolist()\n",
    "\n",
    "print(f'Total classes: {len(class_counts)}')\n",
    "print(f'Negative classes: {len(negative_classes)}')\n",
    "print(f'Positive classes: {len(class_counts) - len(negative_classes)}')\n",
    "\n",
    "# Add 'Hen' to the list of negative classes\n",
    "if 'Hen' not in negative_classes:\n",
    "    negative_classes.append('Hen')\n",
    "\n",
    "# Mark negative classes and 'Hen' as background (0)\n",
    "df['target'] = df['label'].apply(lambda x: 0 if x in negative_classes else x)\n",
    "\n",
    "# Convert labels to categorical data and get the numeric codes\n",
    "df['target'] = pd.Categorical(df['target']).codes\n",
    "\n",
    "# filter out images with only negative classes\n",
    "df = df.groupby('img_name').filter(lambda x: x['target'].ne(0).any())\n",
    "\n",
    "# filter out images with invalid bounding boxes\n",
    "df = df.groupby('img_name').filter(lambda x: ((x['xmin'] < x['xmax']) & (x['ymin'] < x['ymax'])).all())\n",
    "\n",
    "# Create a dictionary using df['label'] as the keys and df['target'] as the values\n",
    "label_dict = dict(zip(df['target'], df['label']))\n",
    "\n",
    "# change label_dict key '0' value to 'background'\n",
    "label_dict[0] = 'NEGATIVE'\n",
    "\n",
    "# Drop the original 'label' column from df\n",
    "df = df.drop(['label'], axis=1)\n",
    "\n",
    "# Rename 'target' column to 'label'\n",
    "df.rename(columns={'target': 'label'}, inplace=True)\n",
    "\n",
    "# Save df as csv in directory\n",
    "df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter images after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store unique img_names in filtered df as array\n",
    "img_names = df['img_name'].unique().tolist()\n",
    "\n",
    "# Create a new directory called 'filtered_images'\n",
    "new_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images'\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "else:\n",
    "    for file in os.listdir(new_dir):\n",
    "        os.remove(os.path.join(new_dir, file))\n",
    "\n",
    "# Copy images in img_names to new directory\n",
    "for img in img_names:\n",
    "    shutil.copy2(f'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Images/{img}', new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Transform and Augment Image and Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "from torchvision import transforms as _transforms, tv_tensors\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAVdroneDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset Loader for Waterfowl Drone Imagery\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transforms):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            root_dir (string): Directory containing all images.\n",
    "            transforms (callable): Transformation to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.unique_image_names = self.df['img_name'].unique()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_name = self.unique_image_names[idx]\n",
    "\n",
    "        # Isolate first row to prevent multiple instances of the same image\n",
    "        row = self.df[self.df['img_name'] == image_name].iloc[0]\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, row['img_name'])\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # Convert to Tensor\n",
    "\n",
    "        # Bounding boxes and labels\n",
    "        boxes = self.df[self.df['img_name'] == image_name][['xmin', 'ymin', 'xmax', 'ymax']].values \n",
    "        labels = self.df[self.df['img_name'] == image_name]['label'].values\n",
    "\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)  # (n_objects)\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        # Calculate area\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # Assume no crowd annotations\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "\n",
    "        # Create target dictionary\n",
    "        target = {\n",
    "            'boxes': tv_tensors.BoundingBoxes(boxes, format=tv_tensors.BoundingBoxFormat.XYXY, canvas_size=(image.shape[1], image.shape[2])),\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': area,\n",
    "            'iscrowd': iscrowd\n",
    "        }\n",
    "\n",
    "        image = tv_tensors.Image(image)\n",
    "\n",
    "        if self.transforms:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train: bool): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train (bool): Whether the transform is for training or validation/testing.\n",
    "    \"\"\"\n",
    "    transforms_list = []\n",
    "    transforms_list.append(T.ToImage())\n",
    "    transforms_list.append(T.ToDtype(torch.float32, scale=True))\n",
    "    if train:\n",
    "        transforms_list.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms_list.append(T.RandomApply([T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)], p=0.25))\n",
    "        transforms_list.append(T.RandomApply([T.GaussianBlur(kernel_size=1, sigma=(0.05, 0.25))], p=0.25))\n",
    "        transforms_list.append(T.RandomIoUCrop(min_scale=0.75, max_scale=1.5, min_aspect_ratio=16/9, max_aspect_ratio=16/9))\n",
    "        transforms_list.append(T.ClampBoundingBoxes())\n",
    "        transforms_list.append(T.SanitizeBoundingBoxes())\n",
    "    transforms_list.append(T.Resize(size=(800,), max_size=1333, interpolation=T.InterpolationMode.BILINEAR))\n",
    "    return T.Compose(transforms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for plotting image and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are values in label_dict\n",
    "classes = list(label_dict.values())\n",
    "\n",
    "# reverse label dictionary for mapping predictions to classes\n",
    "rev_label_dict = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# distinct colors \n",
    "bbox_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: bbox_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    " \n",
    "\n",
    "def plot_bbox(ax, boxes, labels):\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    # add label text to bounding box using label_dict if label exists else labels\n",
    "    ax.text(boxes[:, 2], boxes[:, 3], \n",
    "            (label_dict[labels.item()] if labels.item() in label_dict else labels.item()),\n",
    "            fontsize = 8,\n",
    "            bbox = dict(facecolor = 'white', alpha = 0.8, pad = 0, edgecolor = 'none'),\n",
    "            color = 'black')\n",
    "\n",
    "\n",
    "# function for plotting all boxes and labels on the image using get_polygon, img_show, and plot_mask functions\n",
    "def plot_detections(image, boxes, labels, ax = None):\n",
    "    ax = img_show(image.permute(1, 2, 0), ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox(ax, box, labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot sample batch to confirm data loads and transforms correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample batch of data to custom PyTorch Dataset and Transform\n",
    "sample_dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv', \n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images', \n",
    "                                transforms = get_transform(train = True))\n",
    "\n",
    "sample_data_loader = torch.utils.data.DataLoader(sample_dataset, batch_size = 8, shuffle = True, \n",
    "                                             collate_fn = utils.collate_fn, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store images and annotation targets from sample batch\n",
    "batch = next(iter(sample_data_loader))\n",
    "images, targets = batch\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "images = [np.clip(image, 0, 1) for image in images]\n",
    "\n",
    "# Plot the all samples from batch in a grid of subplots.\n",
    "plt.figure(figsize =(12, int(sample_data_loader.batch_size)*4))\n",
    "for i in range(int(sample_data_loader.batch_size)):\n",
    "    ax = plt.subplot(int(sample_data_loader.batch_size), 2, 1 + i)\n",
    "    plot_detections(images[i], targets[i]['boxes'], targets[i]['labels'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample {i + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load RetinaNet with ResNet FPN backbone and add alpha, gamma, and dropout params\n",
    "##### Adapted from: https://arxiv.org/abs/1708.02002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import RetinaNet\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead, RetinaNetRegressionHead\n",
    "from typing import Optional, Callable, List\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "def _sum(x: List[torch.Tensor]) -> torch.Tensor:\n",
    "    res = x[0]\n",
    "    for i in x[1:]:\n",
    "        res = res + i\n",
    "    return res\n",
    "\n",
    "class CustomRetinaNetClassificationHead(RetinaNetClassificationHead):\n",
    "    def __init__(self, in_channels, num_anchors, num_classes, alpha=0.25, gamma_loss=2.0, prior_probability=0.01, norm_layer: Optional[Callable[..., nn.Module]] = None, dropout_prob=0.05):\n",
    "        super().__init__(in_channels, num_anchors, num_classes, prior_probability, norm_layer)\n",
    "        self.alpha = alpha\n",
    "        self.gamma_loss = gamma_loss\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def compute_loss(self, targets, head_outputs, matched_idxs):\n",
    "        losses = []\n",
    "\n",
    "        cls_logits = head_outputs[\"cls_logits\"]\n",
    "\n",
    "        for targets_per_image, cls_logits_per_image, matched_idxs_per_image in zip(targets, cls_logits, matched_idxs):\n",
    "            # determine only the foreground\n",
    "            foreground_idxs_per_image = matched_idxs_per_image >= 0\n",
    "            num_foreground = foreground_idxs_per_image.sum()\n",
    "\n",
    "            # create the target classification\n",
    "            gt_classes_target = torch.zeros_like(cls_logits_per_image)\n",
    "            gt_classes_target[\n",
    "                foreground_idxs_per_image,\n",
    "                targets_per_image[\"labels\"][matched_idxs_per_image[foreground_idxs_per_image]],\n",
    "            ] = 1.0\n",
    "\n",
    "            # find indices for which anchors should be ignored\n",
    "            valid_idxs_per_image = matched_idxs_per_image != self.BETWEEN_THRESHOLDS\n",
    "\n",
    "            # compute the classification loss with custom alpha and gamma_loss\n",
    "            losses.append(\n",
    "                sigmoid_focal_loss(\n",
    "                    cls_logits_per_image[valid_idxs_per_image],\n",
    "                    gt_classes_target[valid_idxs_per_image],\n",
    "                    alpha=self.alpha,\n",
    "                    gamma=self.gamma_loss,\n",
    "                    reduction=\"sum\",\n",
    "                )\n",
    "                / max(1, num_foreground)\n",
    "            )\n",
    "\n",
    "        return _sum(losses) / len(targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_cls_logits = []\n",
    "        for features in x:\n",
    "            cls_logits = self.conv(features)\n",
    "            cls_logits = self.dropout(cls_logits)  # Apply dropout\n",
    "            cls_logits = self.cls_logits(cls_logits)\n",
    "\n",
    "            # Permute classification output from (N, A * K, H, W) to (N, HWA, K).\n",
    "            N, _, H, W = cls_logits.shape\n",
    "            cls_logits = cls_logits.view(N, -1, self.num_classes, H, W)\n",
    "            cls_logits = cls_logits.permute(0, 3, 4, 1, 2)\n",
    "            cls_logits = cls_logits.reshape(N, -1, self.num_classes)  # Size=(N, HWA, K)\n",
    "\n",
    "            all_cls_logits.append(cls_logits)\n",
    "\n",
    "        return torch.cat(all_cls_logits, dim=1)\n",
    "\n",
    "class CustomRetinaNetRegressionHead(RetinaNetRegressionHead):\n",
    "    def __init__(self, in_channels, num_anchors, norm_layer: Optional[Callable[..., nn.Module]] = None, dropout_prob=0.05):\n",
    "        super().__init__(in_channels, num_anchors, norm_layer)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_bbox_regression = []\n",
    "        for features in x:\n",
    "            bbox_regression = self.conv(features)\n",
    "            bbox_regression = self.dropout(bbox_regression)  # Apply dropout\n",
    "            bbox_regression = self.bbox_reg(bbox_regression)\n",
    "\n",
    "            # Permute bbox regression output from (N, 4 * A, H, W) to (N, HWA, 4).\n",
    "            N, _, H, W = bbox_regression.shape\n",
    "            bbox_regression = bbox_regression.view(N, -1, 4, H, W)\n",
    "            bbox_regression = bbox_regression.permute(0, 3, 4, 1, 2)\n",
    "            bbox_regression = bbox_regression.reshape(N, -1, 4)  # Size=(N, HWA, 4)\n",
    "\n",
    "            all_bbox_regression.append(bbox_regression)\n",
    "\n",
    "        return torch.cat(all_bbox_regression, dim=1)\n",
    "\n",
    "def get_retinanet_model(depth, num_classes, alpha=0.25, gamma_loss=2.0, trainable_backbone_layers=4, dropout_prob=0.05):\n",
    "    # Create the backbone with FPN\n",
    "    if depth == 18:\n",
    "        backbone = resnet_fpn_backbone(backbone_name='resnet18', \n",
    "                                       weights=torchvision.models.ResNet18_Weights.DEFAULT, \n",
    "                                       trainable_layers=trainable_backbone_layers\n",
    "                                       )\n",
    "    elif depth == 34:\n",
    "        backbone = resnet_fpn_backbone(backbone_name='resnet34', \n",
    "                                       weights=torchvision.models.ResNet34_Weights.DEFAULT,\n",
    "                                       trainable_layers=trainable_backbone_layers\n",
    "                                       )\n",
    "    elif depth == 50:\n",
    "        backbone = resnet_fpn_backbone(backbone_name='resnet50', \n",
    "                                       weights=torchvision.models.ResNet50_Weights.DEFAULT,\n",
    "                                       trainable_layers=trainable_backbone_layers\n",
    "                                       )\n",
    "    elif depth == 101:\n",
    "        backbone = resnet_fpn_backbone(backbone_name='resnet101', \n",
    "                                       weights=torchvision.models.ResNet101_Weights.DEFAULT, \n",
    "                                       trainable_layers=trainable_backbone_layers\n",
    "                                       )\n",
    "    elif depth == 152:\n",
    "        backbone = resnet_fpn_backbone(backbone_name='resnet152', \n",
    "                                       weights=torchvision.models.ResNet152_Weights.DEFAULT, \n",
    "                                       trainable_layers=trainable_backbone_layers\n",
    "                                       )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model depth\")\n",
    "\n",
    "    # Create the RetinaNet model with the custom backbone\n",
    "    model = RetinaNet(backbone, num_classes=num_classes)\n",
    "\n",
    "    # Replace the classification head with the custom one\n",
    "    in_channels = model.head.classification_head.cls_logits.in_channels\n",
    "    num_anchors = model.head.classification_head.num_anchors\n",
    "    model.head.classification_head = CustomRetinaNetClassificationHead(in_channels, num_anchors, num_classes, alpha=alpha, gamma_loss=gamma_loss, dropout_prob=dropout_prob)\n",
    "\n",
    "    # Replace the regression head with the custom one\n",
    "    model.head.regression_head = CustomRetinaNetRegressionHead(in_channels, num_anchors, dropout_prob=dropout_prob)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_retinanet_model(depth = 101, num_classes=len(classes), alpha=0.5, gamma_loss=3.0, trainable_backbone_layers=4, dropout_prob=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use stratified sampling to split multi-label dataset into train, val, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random number generator for reproducible data splits\n",
    "rng = np.random.default_rng(np.random.MT19937(np.random.SeedSequence(51)))\n",
    "\n",
    "# Group annotations by image\n",
    "image_groups = df.groupby('img_name')\n",
    "\n",
    "# Create a dictionary to store the class distribution for each image\n",
    "image_class_distribution = {}\n",
    "\n",
    "# Populate the dictionary with class distributions\n",
    "for image_name, group in image_groups:\n",
    "    labels = group['label'].tolist()\n",
    "    image_class_distribution[image_name] = labels\n",
    "\n",
    "# Create a list of all image names and their corresponding labels\n",
    "all_images = list(image_class_distribution.keys())\n",
    "all_labels = [image_class_distribution[image] for image in all_images]\n",
    "\n",
    "# Convert labels to a binary matrix for stratification\n",
    "unique_labels = sorted(df['label'].unique())\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "binary_labels = np.zeros((len(all_images), len(unique_labels)), dtype=int)\n",
    "\n",
    "for i, labels in enumerate(all_labels):\n",
    "    for label in labels:\n",
    "        binary_labels[i, label_to_index[label]] = 1\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.05\n",
    "\n",
    "# Function to perform stratified sampling\n",
    "def stratified_split(all_images, binary_labels, train_ratio, val_ratio, rng):\n",
    "    n_samples = len(all_images)\n",
    "    indices = np.arange(n_samples)\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    class_counts = np.sum(binary_labels, axis=0)\n",
    "    train_class_counts = np.zeros_like(class_counts)\n",
    "    val_class_counts = np.zeros_like(class_counts)\n",
    "    test_class_counts = np.zeros_like(class_counts)\n",
    "\n",
    "    for idx in indices:\n",
    "        label_vector = binary_labels[idx]\n",
    "        if np.all(train_class_counts + label_vector <= train_ratio * class_counts):\n",
    "            train_indices.append(idx)\n",
    "            train_class_counts += label_vector\n",
    "        elif np.all(val_class_counts + label_vector <= val_ratio * class_counts):\n",
    "            val_indices.append(idx)\n",
    "            val_class_counts += label_vector\n",
    "        else:\n",
    "            test_indices.append(idx)\n",
    "            test_class_counts += label_vector\n",
    "\n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "# Perform stratified split\n",
    "train_indices, val_indices, test_indices = stratified_split(all_images, binary_labels, train_ratio, val_ratio, rng)\n",
    "\n",
    "# Map image names to unique indices\n",
    "image_to_unique_index = {image: idx for idx, image in enumerate(df['img_name'].unique())}\n",
    "\n",
    "# Create lists of unique indices for each split\n",
    "train_indices = [image_to_unique_index[all_images[idx]] for idx in train_indices]\n",
    "val_indices = [image_to_unique_index[all_images[idx]] for idx in val_indices]\n",
    "test_indices = [image_to_unique_index[all_images[idx]] for idx in test_indices]\n",
    "\n",
    "# Function to get class distribution\n",
    "def get_class_distribution(images, image_class_distribution):\n",
    "    class_counts = defaultdict(int)\n",
    "    for image in images:\n",
    "        for label in image_class_distribution[image]:\n",
    "            class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "# Get train, val, and test images\n",
    "train_images = [all_images[idx] for idx in train_indices]\n",
    "val_images = [all_images[idx] for idx in val_indices]\n",
    "test_images = [all_images[idx] for idx in test_indices]\n",
    "\n",
    "train_class_distribution = get_class_distribution(train_images, image_class_distribution)\n",
    "val_class_distribution = get_class_distribution(val_images, image_class_distribution)\n",
    "test_class_distribution = get_class_distribution(test_images, image_class_distribution)\n",
    "\n",
    "class_indices = {label: [] for label in df['label'].unique()}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    class_indices[row['label']].append(idx)\n",
    "\n",
    "train_class_distribution = {k: v / len(class_indices[k]) for k, v in train_class_distribution.items()}\n",
    "val_class_distribution = {k: v / len(class_indices[k]) for k, v in val_class_distribution.items()}\n",
    "test_class_distribution = {k: v / len(class_indices[k]) for k, v in test_class_distribution.items()}\n",
    "\n",
    "print(\"Train class distribution:\", dict(sorted(train_class_distribution.items())))\n",
    "print(\"Validation class distribution:\", dict(sorted(val_class_distribution.items())))\n",
    "print(\"Test class distribution:\", dict(sorted(test_class_distribution.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create weighted random sampler to handle class imbalances during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_labels is a list of lists, where each list contains the labels for an image\n",
    "train_labels = [image_class_distribution[image] for image in train_images]\n",
    "\n",
    "# Flatten the list of lists into a single list of labels\n",
    "flattened_train_labels = [label for sublist in train_labels for label in sublist]\n",
    "\n",
    "# Calculate class counts (ignoring background/negative class)\n",
    "train_class_counts = pd.Series([label for label in flattened_train_labels if label != 0]).value_counts().sort_index().tolist()\n",
    "\n",
    "# Calculate the total count of labels\n",
    "train_total_count = sum(train_class_counts)\n",
    "\n",
    "# Calculate class weights\n",
    "train_class_weights = [train_total_count / count for count in train_class_counts]\n",
    "train_class_weights = torch.tensor(train_class_weights, dtype=torch.float32)\n",
    "\n",
    "# store label weights for each train image \n",
    "train_label_weights = [torch.tensor([train_class_weights[label - 1] for label in labels], dtype=torch.float32) for labels in train_labels]\n",
    "\n",
    "# Calculate the average weight for each image\n",
    "train_image_weights = [torch.mean(weights).item() for weights in train_label_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.WeightedRandomSampler(train_image_weights, len(train_image_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Tune Model Hyperparameters using Ray Tune**</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ray Tune trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "from engine_gradientAccumulation import train_one_epoch, evaluate\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB\n",
    "from pathlib import Path\n",
    "import ray.cloudpickle as pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducible training\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "def train_MAVdroneDataset(config):\n",
    "    import ray\n",
    "    import torch\n",
    "    import utils\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import ray.cloudpickle as pickle\n",
    "    from torch_lr_finder import LRFinder, TrainDataLoaderIter\n",
    "\n",
    "    # Custom data loader iterator\n",
    "    class CustomTrainDataLoaderIter(TrainDataLoaderIter):\n",
    "        def inputs_labels_from_batch(self, batch_data):\n",
    "            inputs = [image.to('cuda') for image in batch_data[0]]\n",
    "            labels = [{k: v.to('cuda') for k, v in t.items()} for t in batch_data[1]]\n",
    "            return inputs, labels\n",
    "\n",
    "    # function for finding optimal learning rate given hyperparameters\n",
    "    def train_lr_finder(config, dataset_train, accumulation_steps):\n",
    "        # Create data loader\n",
    "        data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=config[\"batch_size\"],\n",
    "                                                    sampler=config[\"train_sampler\"],\n",
    "                                                    collate_fn=utils.collate_fn,\n",
    "                                                    num_workers=0, pin_memory=True)\n",
    "\n",
    "        # Construct custom RetinaNet model (do this inside function to avoid conflicts with main function)\n",
    "        model = get_retinanet_model(\n",
    "            depth=config[\"resnet\"], num_classes=len(classes), alpha=config[\"alpha\"], \n",
    "            gamma_loss=config[\"gamma_loss\"], trainable_backbone_layers=int(config[\"backbone_lyrs\"]), \n",
    "            dropout_prob=0.05\n",
    "        ).to('cuda')\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(), lr=1e-7, momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "\n",
    "        # Create custom iterator\n",
    "        train_iter = CustomTrainDataLoaderIter(data_loader_train)\n",
    "\n",
    "        grad_scaler = torch.GradScaler()\n",
    "\n",
    "        amp_config = {\n",
    "            'device_type': 'cuda',\n",
    "        }\n",
    "\n",
    "        # Use LRFinder to find optimal learning rate\n",
    "        class CustomLRFinder(LRFinder):\n",
    "            def __init__(self, model, optimizer, criterion, device=None, amp_backend=\"native\", amp_config=None, grad_scaler=None):\n",
    "                super().__init__(model, optimizer, criterion, device)\n",
    "                self.amp_backend = amp_backend\n",
    "                self.amp_config = amp_config\n",
    "                self.grad_scaler = grad_scaler or torch.GradScaler()\n",
    "\n",
    "            def _train_batch(self, train_iter, accumulation_steps, non_blocking_transfer=True):\n",
    "                self.model.train()\n",
    "                total_loss = 0\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                for _ in range(accumulation_steps):\n",
    "                    inputs, labels = next(train_iter)\n",
    "                    inputs, labels = self._move_to_device(inputs, labels, non_blocking=non_blocking_transfer)\n",
    "\n",
    "                    # Forward pass with mixed precision\n",
    "                    with torch.autocast(device_type=\"cuda\"):\n",
    "                        outputs = self.model(inputs, labels)  # Ensure targets are passed here\n",
    "                        loss = sum(loss for loss in outputs.values())  # Sum the losses\n",
    "\n",
    "                    # loss should be averaged in each step\n",
    "                    loss /= accumulation_steps\n",
    "\n",
    "                    # Backward pass with mixed precision\n",
    "                    self.grad_scaler.scale(loss).backward()\n",
    "\n",
    "                    total_loss += loss\n",
    "\n",
    "                self.grad_scaler.step(self.optimizer)\n",
    "                self.grad_scaler.update()\n",
    "\n",
    "                return total_loss.item()\n",
    "\n",
    "        # Use the custom LRFinder\n",
    "        lr_finder = CustomLRFinder(model, optimizer, None, device='cuda', amp_backend='torch', amp_config=amp_config, grad_scaler=grad_scaler)\n",
    "\n",
    "        lr_finder.range_test(train_iter, \n",
    "                            end_lr=1, \n",
    "                            num_iter=100, \n",
    "                            step_mode='exp', \n",
    "                            accumulation_steps=accumulation_steps \n",
    "                            )\n",
    "\n",
    "        # Plot the learning rate finder results\n",
    "        ax, suggested_lr = lr_finder.plot()\n",
    "        \n",
    "        lr_finder.reset()\n",
    "\n",
    "        return suggested_lr\n",
    "\n",
    "    # Set random seed for reproducible training\n",
    "    set_seed(51) \n",
    "    \n",
    "    # Get dataset references directly from config\n",
    "    dataset_train = ray.get(config[\"dataset_train_ref\"])\n",
    "    data_loader_val = ray.get(config[\"data_loader_val_ref\"])\n",
    "    train_coco_ds = ray.get(config[\"train_coco_ds_ref\"])\n",
    "    val_coco_ds = ray.get(config[\"val_coco_ds_ref\"])\n",
    "\n",
    "    # Use gradient accumulation due to memory constraints (batch_size=16 maxes out GPU)\n",
    "    training_steps = [\n",
    "        {\"step\": 0, \"batch_size\": config[\"batch_size\"], \"epochs\": 20, \"print_freq\": 25, \"accumulation_steps\": 8}, # [ 4*8 ] --> 32\n",
    "        {\"step\": 1, \"batch_size\": config[\"batch_size\"], \"epochs\": 15, \"print_freq\": 25, \"accumulation_steps\": 16}, # [ 4*16 ] --> 64\n",
    "        {\"step\": 2, \"batch_size\": config[\"batch_size\"], \"epochs\": 10, \"print_freq\": 25, \"accumulation_steps\": 32}, # [ 4*32 ] --> 128\n",
    "        {\"step\": 3, \"batch_size\": config[\"batch_size\"], \"epochs\": 5, \"print_freq\": 25, \"accumulation_steps\": 64} # [ 4*64 ] --> 256\n",
    "    ]\n",
    "\n",
    "    # Determine the optimal learning rate given hyperparameter configuration\n",
    "    suggested_lr = train_lr_finder(config, dataset_train, training_steps[0][\"accumulation_steps\"])\n",
    "\n",
    "    # add optimal lr to config\n",
    "    config[\"lr\"] = suggested_lr\n",
    "\n",
    "    # Construct custom RetinaNet model\n",
    "    model = get_retinanet_model(depth=config[\"resnet\"],\n",
    "                                num_classes=len(classes), \n",
    "                                alpha=config[\"alpha\"], \n",
    "                                gamma_loss=config[\"gamma_loss\"],\n",
    "                                trainable_backbone_layers=int(config[\"backbone_lyrs\"]),\n",
    "                                dropout_prob=0.05)\n",
    "\n",
    "    # Explicitly set CUDA_VISIBLE_DEVICES\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "    # Force reinitialization of CUDA context\n",
    "    torch.cuda.device_count()\n",
    "\n",
    "    device = \"cpu\" \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    model.to(device)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=suggested_lr,\n",
    "                                momentum=config[\"momentum\"], \n",
    "                                weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=int(config[\"step_size\"]),\n",
    "                                                   gamma=config[\"gamma_lr\"])\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    checkpoint = train.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"] + 1\n",
    "            model.load_state_dict(checkpoint_state[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "            current_step = checkpoint_state[\"current_step\"]\n",
    "            batch_size = checkpoint_state[\"batch_size\"]\n",
    "            accumulation_steps = checkpoint_state[\"accumulation_steps\"]\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        current_step = 0\n",
    "        batch_size = config[\"batch_size\"]\n",
    "        accumulation_steps = 1\n",
    "\n",
    "    # Initialize step index\n",
    "    step_index = current_step\n",
    "\n",
    "    # loop through training_steps during training to increase batch size\n",
    "    while step_index < len(training_steps):\n",
    "        step = training_steps[step_index]\n",
    "\n",
    "        batch_size = step['batch_size']\n",
    "        total_epochs = step['epochs']\n",
    "        print_freq = step['print_freq']\n",
    "        accumulation_steps = step['accumulation_steps']\n",
    "\n",
    "        # Calculate the remaining epochs for the current step\n",
    "        remaining_epochs = total_epochs - (start_epoch % total_epochs)\n",
    "\n",
    "        # use the sampler for weighted sampling to address class imbalances\n",
    "        data_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
    "                                                  sampler=config[\"train_sampler\"],\n",
    "                                                  collate_fn=utils.collate_fn,\n",
    "                                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "        print(f'Training step {step[\"step\"]}... batch size: {batch_size*accumulation_steps}')\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch + remaining_epochs):\n",
    "            train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, device,\n",
    "                                                                     epoch, print_freq, accumulation_steps,\n",
    "                                                                     data_loader_val)\n",
    "\n",
    "            # evaluate on the val dataset\n",
    "            train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader_val, val_coco_ds, device, data_loader, train_coco_ds)\n",
    "\n",
    "            # update the learning rate\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            checkpoint_data = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"current_step\": step[\"step\"],\n",
    "                \"batch_size\": batch_size,\n",
    "                \"accumulation_steps\": accumulation_steps,\n",
    "            }\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "                data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "                with open(data_path, \"wb\") as fp:\n",
    "                    pickle.dump(checkpoint_data, fp)\n",
    "                train.report(\n",
    "                    {\"epoch\": epoch,\n",
    "                     \"lr\": suggested_lr,\n",
    "                     \"train_loss\": train_metric_logger.loss.avg,  # metric_logger object\n",
    "                     \"val_loss\": val_metric_logger.loss.avg,\n",
    "                     \"train_mAP\": train_coco_evaluator.coco_eval['bbox'].stats[0],  # mAP (IoU=0.50:0.95)\n",
    "                     \"val_mAP\": val_coco_evaluator.coco_eval['bbox'].stats[0],\n",
    "                     \"train_mAR\": train_coco_evaluator.coco_eval['bbox'].stats[8],  # mAR (IoU=0.50:0.95)\n",
    "                     \"val_mAR\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                     \"train_f1\": calculate_f1_score(train_coco_evaluator.coco_eval['bbox'].stats[0],  # AP (IoU=0.50:0.95)\n",
    "                                                    train_coco_evaluator.coco_eval['bbox'].stats[8]  # AR (IoU=0.50:0.95)\n",
    "                                                    ),\n",
    "                     \"val_f1\": calculate_f1_score(val_coco_evaluator.coco_eval['bbox'].stats[0],\n",
    "                                                  val_coco_evaluator.coco_eval['bbox'].stats[8]\n",
    "                                                  )},\n",
    "                     checkpoint=train.Checkpoint.from_directory(checkpoint_dir),\n",
    "                )\n",
    "\n",
    "        # set start_epoch to the next epoch for the next training step\n",
    "        start_epoch += remaining_epochs\n",
    "        step_index += 1\n",
    "\n",
    "    print('Tuning Trial Complete!')\n",
    "\n",
    "\n",
    "# test set accuracy of best model\n",
    "def test_best_model(best_trial, best_checkpoint):\n",
    "    best_model =  get_retinanet_model(depth=best_trial.config[\"resnet\"],\n",
    "                                      num_classes=len(classes), \n",
    "                                      alpha = best_trial.config[\"alpha\"], \n",
    "                                      gamma_loss=best_trial.config[\"gamma_loss\"],\n",
    "                                      trainable_backbone_layers = int(best_trial.config[\"backbone_lyrs\"]),\n",
    "                                      dropout_prob = 0.05)\n",
    "                                      \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        \n",
    "    best_model.to(device)\n",
    "\n",
    "    with best_checkpoint.as_directory() as checkpoint_dir:\n",
    "        data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "        with open(data_path, \"rb\") as fp:\n",
    "            best_checkpoint_data = pickle.load(fp)\n",
    "\n",
    "        best_model.load_state_dict(best_checkpoint_data[\"model_state_dict\"])\n",
    "\n",
    "    data_loader_test = ray.get(best_trial.config[\"data_loader_test_ref\"])\n",
    "    test_coco_ds = ray.get(best_trial.config[\"test_coco_ds_ref\"]) \n",
    "    \n",
    "    test_results = evaluate(best_model, data_loader_test, test_coco_ds, device, train_data_loader=None, train_coco_ds=None)\n",
    "\n",
    "    print(f'Best trial test set mAP: {test_results.coco_eval[\"bbox\"].stats[0]}') # IoU=0.50:0.95\n",
    "    print(f'Best trial test set mAR: {test_results.coco_eval[\"bbox\"].stats[8]}') # IoU=0.50:0.95\n",
    "    print(f'Best trial test set f1-score: {calculate_f1_score(test_results.coco_eval[\"bbox\"].stats[0], test_results.coco_eval[\"bbox\"].stats[8])}') # IoU=0.50:0.95\n",
    "\n",
    "\n",
    "def trial_dirname_creator(trial):\n",
    "    return f\"{trial.trial_id}\"\n",
    "\n",
    "\n",
    "def create_coco_datasets(train_dataset, val_dataset, test_dataset):\n",
    "    \"\"\"\n",
    "    Create COCO dataset objects from torch.utils.data.Dataset using get_coco_api_from_dataset.\n",
    "    This function creates the COCO dataset objects in parallel.\n",
    "    \n",
    "    :param train_dataset: torch.utils.data.Dataset\n",
    "    :param val_dataset: torch.utils.data.Dataset\n",
    "    :param test_dataset: torch.utils.data.Dataset\n",
    "    :return: train_coco_ds, val_coco_ds, test_coco_ds\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        train_future = executor.submit(get_coco_api_from_dataset, train_dataset)\n",
    "        val_future = executor.submit(get_coco_api_from_dataset, val_dataset)\n",
    "        test_future = executor.submit(get_coco_api_from_dataset, test_dataset)\n",
    "\n",
    "        train_coco_ds = train_future.result()\n",
    "        val_coco_ds = val_future.result()\n",
    "        test_coco_ds = test_future.result()\n",
    "\n",
    "    return train_coco_ds, val_coco_ds, test_coco_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Tuning Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples, max_num_epochs, restore_path=\"\"):\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "    os.environ[\"RAY_record_ref_creation_sites\"] = \"1\"\n",
    "    print(ray._private.utils.get_ray_temp_dir())\n",
    "\n",
    "    # Prepare datasets and other configurations\n",
    "    dataset = MAVdroneDataset(\n",
    "        csv_file='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "        root_dir='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/',\n",
    "        transforms=get_transform(train=True)\n",
    "    )\n",
    "\n",
    "    dataset_val = MAVdroneDataset(\n",
    "        csv_file='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "        root_dir='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/',\n",
    "        transforms=get_transform(train=False)\n",
    "    )\n",
    "\n",
    "    dataset_test = MAVdroneDataset(\n",
    "        csv_file='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "        root_dir='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/',\n",
    "        transforms=get_transform(train=False)\n",
    "    )\n",
    "\n",
    "    # Subset using a 80/15/5 split for train, validation, and test datasets\n",
    "    dataset_train = torch.utils.data.Subset(dataset, train_indices)\n",
    "    dataset_val = torch.utils.data.Subset(dataset_val, val_indices)\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, test_indices)\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, batch_size=1, shuffle=False,\n",
    "        collate_fn=utils.collate_fn, num_workers=0, pin_memory=True\n",
    "    )\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False,\n",
    "        collate_fn=utils.collate_fn, num_workers=0, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Create COCO dataset objects for train, val, and test datasets\n",
    "    train_coco_ds, val_coco_ds, test_coco_ds = create_coco_datasets(dataset_train, dataset_val, dataset_test)\n",
    "\n",
    "    # Re-create ObjectRefs\n",
    "    dataset_train_ref = ray.put(dataset_train)\n",
    "    data_loader_val_ref = ray.put(data_loader_val)\n",
    "    data_loader_test_ref = ray.put(data_loader_test)\n",
    "    train_coco_ds_ref = ray.put(train_coco_ds)\n",
    "    val_coco_ds_ref = ray.put(val_coco_ds)\n",
    "    test_coco_ds_ref = ray.put(test_coco_ds)\n",
    "\n",
    "    config = {\n",
    "        \"resnet\": tune.choice([18, 34, 50]),\n",
    "        \"momentum\": tune.uniform(0.4, 0.9),\n",
    "        \"weight_decay\": tune.loguniform(0.00001, 0.01),\n",
    "        \"step_size\": tune.choice([5, 10, 15]),\n",
    "        \"gamma_lr\": tune.uniform(0.1, 0.5),\n",
    "        \"alpha\": tune.uniform(0.2, 0.8),\n",
    "        \"gamma_loss\": tune.uniform(1.5, 3.5),\n",
    "        \"backbone_lyrs\": tune.choice([2, 3, 4]),\n",
    "        \"batch_size\": 4, # constant handle OOM errors when tuning trials concurrently\n",
    "        \"dataset_train_ref\": dataset_train_ref,\n",
    "        \"data_loader_val_ref\": data_loader_val_ref,\n",
    "        \"data_loader_test_ref\": data_loader_test_ref,\n",
    "        \"train_coco_ds_ref\": train_coco_ds_ref,\n",
    "        \"val_coco_ds_ref\": val_coco_ds_ref,\n",
    "        \"test_coco_ds_ref\": test_coco_ds_ref,\n",
    "        \"train_sampler\": train_sampler\n",
    "    }\n",
    "\n",
    "    if tune.Tuner.can_restore(os.path.abspath(restore_path)):\n",
    "        tuner = tune.Tuner.restore(\n",
    "            os.path.abspath(restore_path),\n",
    "            trainable=train_MAVdroneDataset,\n",
    "            param_space=config,  # pass same config with new ObjectRefs\n",
    "            resume_unfinished=True,\n",
    "            resume_errored=False\n",
    "        )\n",
    "        print(f\"Tuner Restored from {restore_path}\")\n",
    "    else:\n",
    "        algo = TuneBOHB(\n",
    "            points_to_evaluate=[\n",
    "                {\"resnet\": 34,\n",
    "                 \"momentum\": 0.9,\n",
    "                 \"weight_decay\": 0.0005,\n",
    "                 \"step_size\": 5,\n",
    "                 \"gamma_lr\": 0.1,\n",
    "                 \"alpha\": 0.7,\n",
    "                 \"gamma_loss\": 3.0,\n",
    "                 \"backbone_lyrs\": 4}\n",
    "            ],  # starting point for search\n",
    "            seed=51  # set for identical initial configurations\n",
    "        )\n",
    "\n",
    "        algo = ConcurrencyLimiter(algo, max_concurrent=2)\n",
    "\n",
    "        scheduler = HyperBandForBOHB(\n",
    "            time_attr=\"training_iteration\",\n",
    "            max_t=int(max_num_epochs),\n",
    "            reduction_factor=4,\n",
    "            stop_last_trials=False,\n",
    "        )\n",
    "\n",
    "        reporter = JupyterNotebookReporter(overwrite=True,\n",
    "            metric_columns=[\"epoch\", \"lr\", \"train_loss\", \"val_loss\", \"train_mAP\", \"val_mAP\", \"train_mAR\", \"val_mAR\", \"train_f1\", \"val_f1\"],\n",
    "            parameter_columns=[\"resnet\", \"momentum\", \"weight_decay\", \"step_size\", \"gamma_lr\", \"batch_size\", \"alpha\", \"gamma_loss\", \"backbone_lyrs\"],\n",
    "            sort_by_metric=True\n",
    "        )\n",
    "\n",
    "        # Dictionary to store train_f1 scores for each trial\n",
    "        val_f1_history = defaultdict(list)\n",
    "\n",
    "        def custom_stop(trial_id, result):\n",
    "            # Ensure the required keys are in the result dictionary\n",
    "            required_keys = [\"training_iteration\", \"val_f1\"]\n",
    "            if all(key in result for key in required_keys):\n",
    "                # Append the current val_f1 score to the trial's history\n",
    "                val_f1_history[trial_id].append(result[\"val_f1\"])\n",
    "                \n",
    "                # Check if there are at least 5 epochs recorded\n",
    "                if len(val_f1_history[trial_id]) >= 5:\n",
    "                    # Calculate the improvement over the last 5 epochs\n",
    "                    initial_f1 = val_f1_history[trial_id][-5]\n",
    "                    current_f1 = val_f1_history[trial_id][-1]\n",
    "                    \n",
    "                    # Check if initial_f1 is zero to avoid division by zero\n",
    "                    if initial_f1 == 0:\n",
    "                        if current_f1 == 0:\n",
    "                            return True  # No improvement if both initial and current f1 are zero (Stop)\n",
    "                        improvement = float('inf')  # Set improvement to infinity if initial_f1 is zero but current_f1 is not to avoid zero division\n",
    "                    else:\n",
    "                        improvement = (current_f1 - initial_f1) / initial_f1\n",
    "                    \n",
    "                    # Check if the improvement is less than 0.5%\n",
    "                    if improvement < 0.005:\n",
    "                        return True # (Stop)\n",
    "            return False\n",
    "\n",
    "        tuner = tune.Tuner(\n",
    "            tune.with_resources(\n",
    "                train_MAVdroneDataset,\n",
    "                resources={\"cpu\": 18.0, \"gpu\": float(1/2)} # each trial uses 12 CPUs and 0.5 GPU\n",
    "            ),\n",
    "            run_config=train.RunConfig(\n",
    "                name=f\"BOHB_RetinaNet_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "                failure_config=train.FailureConfig(max_failures=2),\n",
    "                stop=custom_stop,\n",
    "                progress_reporter=reporter,\n",
    "            ),\n",
    "            tune_config=tune.TuneConfig(\n",
    "                metric=\"val_f1\",\n",
    "                mode=\"max\",\n",
    "                search_alg=algo,\n",
    "                scheduler=scheduler,\n",
    "                num_samples=int(num_samples),\n",
    "                trial_dirname_creator=trial_dirname_creator\n",
    "            ),\n",
    "            param_space=config\n",
    "        )\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_trial = results.get_best_result(\"val_f1\", \"max\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print()\n",
    "    print(\"Best trial final training loss: {}\".format(best_trial.metrics[\"train_loss\"]))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.metrics[\"val_loss\"]))\n",
    "    print(\"Best trial final training mAP: {}\".format(best_trial.metrics[\"train_mAP\"]))\n",
    "    print(\"Best trial final validation mAP: {}\".format(best_trial.metrics[\"val_mAP\"]))\n",
    "    print(\"Best trial final training mAR: {}\".format(best_trial.metrics[\"train_mAR\"]))\n",
    "    print(\"Best trial final validation mAR: {}\".format(best_trial.metrics[\"val_mAR\"]))\n",
    "    print(\"Best trial final training f1-score: {}\".format(best_trial.metrics[\"train_f1\"]))\n",
    "    print(\"Best trial final validation f1-score: {}\".format(best_trial.metrics[\"val_f1\"]))\n",
    "    print()\n",
    "\n",
    "    best_checkpoint = best_trial.get_best_checkpoint(metric=\"val_f1\", mode=\"max\")\n",
    "\n",
    "    test_best_model(best_trial, best_checkpoint)\n",
    "\n",
    "    return train_coco_ds, val_coco_ds, test_coco_ds, results, best_trial\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    train_coco_ds, val_coco_ds, test_coco_ds, results, best_trial = main(num_samples=100,\n",
    "                                                                         max_num_epochs=50,\n",
    "                                                                         restore_path=\"C:/Users/exx/ray_results/FALSE\") # set restore_path to the path of the experiment to restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Train Model Using Tuned Hyperparameters**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.profiler\n",
    "\n",
    "def main(train_coco_ds, val_coco_ds, best_trial):\n",
    "    # Set seed\n",
    "    set_seed(51)\n",
    "\n",
    "    batch_size = best_trial.config[\"batch_size\"]\n",
    "\n",
    "    training_steps = [\n",
    "        {\"step\": 0, \"batch_size\": batch_size, \"epochs\": 20, \"print_freq\": 25, \"accumulation_steps\": 4},\n",
    "        {\"step\": 1, \"batch_size\": batch_size, \"epochs\": 15, \"print_freq\": 25, \"accumulation_steps\": 8}, \n",
    "        {\"step\": 2, \"batch_size\": batch_size, \"epochs\": 10, \"print_freq\": 25, \"accumulation_steps\": 16}, \n",
    "        {\"step\": 3, \"batch_size\": batch_size, \"epochs\": 5, \"print_freq\": 25, \"accumulation_steps\": 32} \n",
    "    ]\n",
    "\n",
    "    # load model\n",
    "    model = get_retinanet_model(depth = best_trial.config[\"resnet\"],\n",
    "                                num_classes=len(classes), \n",
    "                                alpha = best_trial.config[\"alpha\"], \n",
    "                                gamma_loss=best_trial.config[\"gamma_loss\"],\n",
    "                                trainable_backbone_layers = int(best_trial.config[\"backbone_lyrs\"]),\n",
    "                                dropout_prob = 0.05)\n",
    "\n",
    "    device = \"cpu\" \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer - SGD w/ momentum and weight decay\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=best_trial.config[\"lr\"],\n",
    "                                momentum=best_trial.config[\"momentum\"], \n",
    "                                weight_decay=best_trial.config[\"weight_decay\"])\n",
    "    \n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size=best_trial.config[\"step_size\"],\n",
    "                                                    gamma=best_trial.config[\"gamma_lr\"])\n",
    "\n",
    "    # initialize tensorboard writer in folder named f\"{current_datetime}\" and using name \"RetinaNet\"\n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    writer = SummaryWriter(log_dir=f'C:/Users/exx/Documents/GitHub/SSD_VGG_PyTorch/runs/RetinaNet/{current_datetime}')\n",
    "\n",
    "    # Store one checkpoint dictionary for each epoch in a list of dictionaries. \n",
    "    checkpoints = []\n",
    "\n",
    "    # Initialize the profiler (https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html)\n",
    "    profiler = torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=1,\n",
    "            warmup=1,\n",
    "            active=3,\n",
    "            repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(writer.log_dir),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    "    )\n",
    "\n",
    "     # load training and val datasets\n",
    "    dataset = MAVdroneDataset(csv_file='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "                                root_dir='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/', \n",
    "                                transforms=get_transform(train=True))\n",
    "\n",
    "    dataset_val = MAVdroneDataset(csv_file='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "                                      root_dir='C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/',\n",
    "                                      transforms=get_transform(train=False))\n",
    "    \n",
    "    # subset using a 80/15/5 split for train, validation, and test datasets\n",
    "    dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    dataset_val = torch.utils.data.Subset(dataset_val, val_indices)\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=1, shuffle=False,\n",
    "                                                      collate_fn=utils.collate_fn, num_workers=0,\n",
    "                                                      pin_memory=True)\n",
    "    \n",
    "    start_epoch = 0\n",
    "\n",
    "    # loop through training_steps during training to increase batch size and decrease learning rate\n",
    "    for step in training_steps:\n",
    "        batch_size = step['batch_size']\n",
    "        num_epochs = step['epochs']\n",
    "        print_freq = step['print_freq']\n",
    "        accumulation_steps = step['accumulation_steps']\n",
    "\n",
    "        # define training and validation data loaders\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                                  sampler=best_trial.config[\"train_sampler\"], \n",
    "                                                  collate_fn=utils.collate_fn, num_workers=0,\n",
    "                                                  pin_memory=True)\n",
    "        \n",
    "        print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size*accumulation_steps}')\n",
    "\n",
    "        #########################################################\n",
    "        ##               The main training loop                ##\n",
    "        #########################################################\n",
    "        with profiler:\n",
    "            for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "                # Monitor memory usage at the start of the epoch\n",
    "                print(f\"Epoch {epoch} - Memory allocated: {torch.cuda.memory_allocated(device)} bytes\")\n",
    "\n",
    "                train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, device, \n",
    "                                                                         epoch, print_freq, accumulation_steps,\n",
    "                                                                         data_loader_val)\n",
    "\n",
    "                # evaluate on the validation dataset\n",
    "                train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader_val, val_coco_ds, device,\n",
    "                                                                    data_loader, train_coco_ds)\n",
    "                \n",
    "                # update the learning rate\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # store training and validation metrics in checkpoint dictionary. \n",
    "                checkpoint = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": train_metric_logger.loss.avg, # average across entire trianing epoch\n",
    "                    \"train_bbox_loss\": train_metric_logger.bbox_regression.avg,\n",
    "                    \"train_class_loss\": train_metric_logger.classification.avg,\n",
    "                    \"val_loss\": val_metric_logger.loss.avg,\n",
    "                    \"val_bbox_loss\": val_metric_logger.bbox_regression.avg,\n",
    "                    \"val_class_loss\": val_metric_logger.classification.avg,\n",
    "                    \"train_mAP_50\": train_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                    \"train_mAR_100\": train_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                    \"val_mAP_50\": val_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                    \"val_mAR_100\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                    \"train_f1\": calculate_f1_score(train_coco_evaluator.coco_eval['bbox'].stats[0], # IoU=0.50:0.95\n",
    "                                                    train_coco_evaluator.coco_eval['bbox'].stats[8] # IoU=0.50:0.95\n",
    "                                                    ),\n",
    "                    \"val_f1\": calculate_f1_score(val_coco_evaluator.coco_eval['bbox'].stats[0],\n",
    "                                                    val_coco_evaluator.coco_eval['bbox'].stats[8]\n",
    "                                                    ),\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict()\n",
    "                }\n",
    "\n",
    "                # append checkpoint to checkpoints list\n",
    "                checkpoints.append(checkpoint)\n",
    "\n",
    "                # report training and validation scalars to tensorboard\n",
    "                writer.add_scalar('Loss/Train', np.array(float(checkpoint[\"train_loss\"])), epoch) # use tags to group scalars\n",
    "                writer.add_scalar('Loss/Val', np.array(float(checkpoint[\"val_loss\"])), epoch)\n",
    "                writer.add_scalar('mAP@50/Train', np.array(float(checkpoint[\"train_mAP_50\"])), epoch)\n",
    "                writer.add_scalar('mAP@50/Val', np.array(float(checkpoint[\"val_mAP_50\"])), epoch)\n",
    "                writer.add_scalar('mAR@100/Train', np.array(float(checkpoint[\"train_mAR_100\"])), epoch)\n",
    "                writer.add_scalar('mAR@100/Val', np.array(float(checkpoint[\"val_mAR_100\"])), epoch)\n",
    "                writer.add_scalar('F1/Train', np.array(float(checkpoint[\"train_f1\"])), epoch)\n",
    "                writer.add_scalar('F1/Val', np.array(float(checkpoint[\"val_f1\"])), epoch)\n",
    "\n",
    "                # Clear CUDA cache and collect garbage to check for memory leaks\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                # Monitor memory usage at the end of the epoch\n",
    "                print(f\"Epoch {epoch} - Max memory allocated: {torch.cuda.max_memory_allocated(device)} bytes\")\n",
    "\n",
    "            # set start_epoch to current epoch for next training step\n",
    "            start_epoch += num_epochs\n",
    "\n",
    "    print('All Training Steps Complete!')\n",
    "\n",
    "    # close tensorboard writer\n",
    "    writer.close()\n",
    "\n",
    "    return checkpoints\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Set environment variable to avoid memory fragmentation\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    \n",
    "    checkpoints = main(train_coco_ds, val_coco_ds, best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best train epoch is dictionary in checkpoints with highest val_mAP_50 value\n",
    "best_train_epoch = max(checkpoints, key = lambda x: x['val_mAP_50'])\n",
    "\n",
    "model = get_retinanet_model(depth = best_trial.config[\"resnet\"],\n",
    "                            num_classes=len(classes), \n",
    "                            alpha = best_trial.config[\"alpha\"], \n",
    "                            gamma_loss = best_trial.config[\"gamma_loss\"],\n",
    "                            trainable_backbone_layers = int(best_trial.config[\"backbone_lyrs\"]),\n",
    "                            dropout_prob = 0.05)\n",
    "\n",
    "# load model weights from best_train_epoch\n",
    "model.load_state_dict(best_train_epoch[\"model_state_dict\"])\n",
    "\n",
    "# save model weights to .pth file\n",
    "torch.save(model.state_dict(), 'RetinaNet_ResNet50_FPN_DuckNet_' + str(datetime.now().strftime(\"%m%d%Y\")) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy checkpoints and remove model and optimizer state dicts\n",
    "checkpoints_copy = checkpoints.copy()\n",
    "for c in checkpoints_copy:\n",
    "    del c[\"model_state_dict\"]\n",
    "    del c[\"optimizer_state_dict\"]\n",
    "\n",
    "# save checkpoints list to text file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/tuned_model_checkpoints.txt', 'w') as f:\n",
    "    for item in checkpoints_copy:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Model Inference on Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of test indices and image names\n",
    "test_dict = dict(zip(test_indices, test_images))\n",
    "\n",
    "# save test_dict to text file just to be safe\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/test_dict.txt', 'w') as f:\n",
    "    for key, value in test_dict.items():\n",
    "        f.write('%s:%s\\n' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/', \n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "# subset test dataset using test_indices\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, test_indices)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 1, shuffle = False,\n",
    "                                               collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                               pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = evaluate(model, data_loader_test, test_coco_ds, device=torch.device('cpu'), train_data_loader=None, train_coco_ds=None)\n",
    "print(f'Best trial test set mAP_50: {test_performance.coco_eval[\"bbox\"].stats[1]}') \n",
    "print(f'Best trial test set mAR_100: {test_performance.coco_eval[\"bbox\"].stats[8]}')\n",
    "print(f'Best trial test set f1 score: {calculate_f1_score(test_performance.coco_eval[\"bbox\"].stats[0], test_performance.coco_eval[\"bbox\"].stats[8])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate performance metrics on every image in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\",\n",
    "                              class_metrics=True,\n",
    "                              max_detection_thresholds=[1, 10, 100]\n",
    "                              )\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for images, targets in data_loader_test:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    # filter targets to only include boxes and labels keys\n",
    "    ground_truth = [{k: v for k, v in t.items() if k in ('boxes', 'labels')} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # calculate mAP and mAR from test dataset\n",
    "    metric.update(prediction, ground_truth)\n",
    "    mean_AP = metric.compute()\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    mean_AP['image_name'] = test_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    results.append(mean_AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-image test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to create a dataframe of image names and mAP values\n",
    "img_results_df = pd.DataFrame()\n",
    "img_results_df['image_name'] = [result['image_name'] for result in results]\n",
    "img_results_df['mAP'] = [result['map'].item() for result in results]\n",
    "img_results_df['mAP_50'] = [result['map_50'].item() for result in results]\n",
    "img_results_df['mAP_75'] = [result['map_75'].item() for result in results]\n",
    "img_results_df['mAP_small'] = [result['map_small'].item() for result in results]\n",
    "img_results_df['mAP_medium'] = [result['map_medium'].item() for result in results]\n",
    "img_results_df['mAP_large'] = [result['map_large'].item() for result in results]\n",
    "img_results_df['mAR_1'] = [result['mar_1'].item() for result in results]\n",
    "img_results_df['mAR_10'] = [result['mar_10'].item() for result in results]\n",
    "img_results_df['mAR_100'] = [result['mar_100'].item() for result in results]\n",
    "img_results_df['mAR_small'] = [result['mar_small'].item() for result in results]\n",
    "img_results_df['mAR_medium'] = [result['mar_medium'].item() for result in results]\n",
    "img_results_df['mAR_large'] = [result['mar_large'].item() for result in results]\n",
    "\n",
    "# # if value is == -1.0, replace with NaN\n",
    "img_results_df = img_results_df.replace(-1.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric values are running averages in torch metrics, so the last value is the final value.\n",
    "final_metrics = img_results_df.iloc[-1]\n",
    "final_metrics = final_metrics.drop('image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-image metrics for test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "cols = ['Metric', 'Value']  \n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# values for column one in table are column names from final_metrics, column two are the column values. \n",
    "for i in range(len(final_metrics)):\n",
    "    x.add_row([final_metrics.index[i], f'{final_metrics[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/testDataset_image_summary_table.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "img_results_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/per_image_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-class test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_res_df = pd.DataFrame()\n",
    "\n",
    "# store 'map_per_class' and 'mar_100_per_class' from results in df\n",
    "class_res_df['image_name'] = [result['image_name'] for result in results]\n",
    "class_res_df['classes'] = [result['classes'] for result in results]\n",
    "class_res_df['map_per_class'] = [result['map_per_class'] for result in results]\n",
    "class_res_df['mar_100_per_class'] = [result['mar_100_per_class'] for result in results]\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: x.numpy())\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: x.numpy())\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: x.numpy())\n",
    "\n",
    "# replace integer labels in classes column with labels using label_dict\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: [label_dict.get(i) for i in x])\n",
    "\n",
    "# replace -1.0 values in map_per_class and mar_100_per_class with NaN\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "\n",
    "# if map_per_class or mar_100_per_class is NaN, delete value from list. Also delete corresponding class label.\n",
    "class_res_df['classes'] = class_res_df.apply(lambda x: [i for i, j in zip(x['classes'], x['map_per_class']) if not np.isnan(j)], axis = 1)\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric values are running averages in TorchMetrics. Store map and mar from last image in dataset\n",
    "classes = class_res_df['classes'].iloc[-1]\n",
    "class_map = class_res_df['map_per_class'].iloc[-1]\n",
    "class_mar_100 = class_res_df['mar_100_per_class'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-class metrics for every image in test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = 'value' and all unique classes\n",
    "cols = ['Class', 'mAP', 'mAR_100']\n",
    "\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# classes go in first column, class_map in second column, and class_mar_100 in third column\n",
    "for i in range(len(classes)):\n",
    "    x.add_row([classes[i], f'{class_map[i]*100:.2f}%', f'{class_mar_100[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/testDataset_class_summary_table.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "class_res_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/per_class_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load test data into one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire test dataset into one batch\n",
    "data_loader_test_singleBatch = torch.utils.data.DataLoader(dataset_test, batch_size = len(dataset_test), shuffle = False,\n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0)\n",
    "\n",
    "# run predictions on all images in the test dataset\n",
    "images, targets = next(iter(data_loader_test_singleBatch))\n",
    "\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "# convert boxes in targets to tensors\n",
    "targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images, targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post-process model predictions for plotting on original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the batch, remove all predicted boxes with scores below 0.5\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['labels'] = predictions[i]['labels'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['scores'] = predictions[i]['scores'][predictions[i]['scores'] > 0.5]\n",
    "\n",
    "# resize boxes to original image shape\n",
    "for i in range(len(images)):\n",
    "    tran_w, tran_h = images[i].shape[1], images[i].shape[2]\n",
    "    \n",
    "    images[i] = Image.open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/' + test_images[i])\n",
    "\n",
    "    orig_w, orig_h = images[i].size\n",
    "\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'] * torch.tensor([orig_w/tran_w, \n",
    "                                                                      orig_h/tran_h, \n",
    "                                                                      orig_w/tran_w,\n",
    "                                                                      orig_h/tran_h]).view(1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Plot Model Predictions for Images in Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    \n",
    "    # add label and score to the bounding box. concatenate label and score to one string. \n",
    "    # use label_dict to replace class numbers with class names\n",
    "    ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "        s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "        color = 'black',\n",
    "        fontsize = 6,\n",
    "        verticalalignment = 'top',\n",
    "        bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "    return ax\n",
    "\n",
    "\n",
    "# function for plotting all predictions on images\n",
    "def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "    ax = img_show(image, ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 32 samples from batch in a grid of subplots.\n",
    "plt.figure(figsize = (24, 36))\n",
    "for i in range(0, 32):\n",
    "    ax = plt.subplot(8, 4, 1 + i)\n",
    "    plot_predictions(images[i], predictions[i]['boxes'], predictions[i]['labels'], predictions[i]['scores'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(test_images[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run inference on full dataset to get model estimates of abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/preprocessed_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/filtered_images/', \n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "data_loader_all = torch.utils.data.DataLoader(dataset_all, batch_size = 1, shuffle = False,\n",
    "                                            collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                            pin_memory = True)\n",
    "\n",
    "# get model predictions for every image in data_loader_all\n",
    "model_predictions_all = []\n",
    "\n",
    "for images, targets in data_loader_all:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    prediction['image_name'] = test_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    model_predictions_all.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert model_predictions_all to a dataframe\n",
    "model_predictions_df = pd.DataFrame(model_predictions_all)\n",
    "\n",
    "# save csv for comparison with ground truth\n",
    "model_predictions_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/model_predictions_full_dataset.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bohb_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
