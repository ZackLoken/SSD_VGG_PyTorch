{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Reading and Cleaning Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion(); # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for processing JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading JSON as dictionary\n",
    "def read_json(filename: str) -> dict:\n",
    "  \n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.loads(f.read())\n",
    "    except:\n",
    "        raise Exception(f\"Reading {filename} file encountered an error\")\n",
    "  \n",
    "    return data\n",
    "\n",
    "# Function to append records to df\n",
    "def create_dataframe(data: list) -> pd.DataFrame:\n",
    "\n",
    "    # Create an empty dataframe to append records\n",
    "    df = pd.DataFrame()\n",
    "  \n",
    "    # Looping through each record\n",
    "    for d in data:\n",
    "          \n",
    "        # Normalize the column levels\n",
    "        record = pd.json_normalize(d)\n",
    "\n",
    "        df = pd.concat([df, record], axis=0)\n",
    "          \n",
    "    return df\n",
    "\n",
    "# Main function to iterate over files in directory and add to df\n",
    "def main():\n",
    "    # Assign directory and empty df for appending annotations\n",
    "    directory = \"C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Annotations/\" # annotation directory\n",
    "    annos_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over files in directory\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            print(f)\n",
    "            \n",
    "        # Read the JSON file as python dictionary \n",
    "        data = read_json(filename = f)\n",
    "    \n",
    "        # Create the dataframe for the array items in annotations key \n",
    "        df = create_dataframe(data = data['annotations'])\n",
    "        df.insert(loc = 0, column = 'img_name', value = f'{f[-30:-5]}.JPG')\n",
    "    \n",
    "        df.rename(columns = {\n",
    "            \"img_name\": \"img_name\",\n",
    "            \"name\": \"label\",\n",
    "            \"bounding_box.h\": \"bbox_height\",\n",
    "            \"bounding_box.w\": \"bbox_width\",\n",
    "            \"bounding_box.x\": \"bbox_x_topLeft\",\n",
    "            \"bounding_box.y\": \"bbox_y_topLeft\",\n",
    "            \"polygon.paths\": \"polygon_path\"\n",
    "        }, inplace = True)\n",
    "        \n",
    "        # Append the df dataframe to the annos_df dataframe\n",
    "        annos_df = pd.concat([annos_df, df], ignore_index=True)\n",
    "\n",
    "    # Convert x, y, h, w to xmin, ymin, xmax, ymax\n",
    "    annos_df.insert(loc = 2, column = 'xmin', \n",
    "                    value = annos_df['bbox_x_topLeft'])\n",
    "    annos_df.insert(loc = 3, column = 'ymin', \n",
    "                    value = annos_df['bbox_y_topLeft'])\n",
    "    annos_df.insert(loc = 4, column = 'xmax', \n",
    "                    value = annos_df['bbox_x_topLeft'] + annos_df['bbox_width'])\n",
    "    annos_df.insert(loc = 5, column = 'ymax', \n",
    "                    value = annos_df['bbox_y_topLeft'] + annos_df['bbox_height']) \n",
    "  \n",
    "    # Drop unneccessary columns \n",
    "    annos_df = annos_df.drop(columns = ['bbox_height', 'bbox_width', 'bbox_x_topLeft', \n",
    "                                        'bbox_y_topLeft', 'id', 'slot_names', 'polygon_path'])\n",
    "        \n",
    "    return annos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load annotation data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main loading function\n",
    "if __name__ == '__main__':\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter annotation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If label value count is less than 200, drop the row\n",
    "df = df.groupby('label').filter(lambda x : len(x) > 200)\n",
    "\n",
    "# If label value is 'Hen', drop the row\n",
    "df = df[df['label'] != 'Hen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter images since most annotation class were filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store unique img_names in filtered df as array\n",
    "img_names = df['img_name'].unique().tolist()\n",
    "\n",
    "# Create a new directory called 'filtered_images'\n",
    "new_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images'\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# Copy images in img_names to new directory\n",
    "for img in img_names:\n",
    "    shutil.copy2(f'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Images/{img}', new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Transform and Augment Image and Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.io import read_image\n",
    "from torchvision import datapoints as dp\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.models.detection import ssd300_vgg16, SSD300_VGG16_Weights\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-process annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ordinal encoder to convert df['label'] to numeric values. 0 is reserved for background class.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "df.insert(loc = 6, column = 'target', value = (oe.fit_transform(df[['label']])) + 1)\n",
    "\n",
    "# Create a dictionary using df['label'] as the keys and df['label_code'] as the values\n",
    "label_dict = dict(zip(df['target'], df['label']))\n",
    "\n",
    "# Drop label column from df\n",
    "df = df.drop(['label'], axis = 1)\n",
    "\n",
    "# Change target column name to label\n",
    "df.rename(columns = {'target': 'label'}, inplace = True)\n",
    "\n",
    "# Save df as csv in directory\n",
    "df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch dataset for custom image and annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset loader (PyTorch) for loading images and annotation data\n",
    "class MAVdroneDataset(Dataset):\n",
    "    \"\"\"Dataset Loader for Waterfowl Drone Imagery\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transforms):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            root_dir (string): Directory containing all images.\n",
    "            transforms (string): train = True for training transforms\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.unique_image_names = self.df['img_name'].unique()\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_name = self.unique_image_names[idx]\n",
    "\n",
    "        # isolate first row prevents multiple instances of the same image\n",
    "        row = self.df[self.df['img_name'] == image_name].iloc[0]\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, row['img_name'])\n",
    "        image = None\n",
    "\n",
    "        # ignore corrupted image data during loading else error\n",
    "        while True:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                buff = BytesIO()\n",
    "                buff.write(f.read())\n",
    "                buff.seek(0)\n",
    "                temp_image = np.array(Image.open(buff), dtype = np.uint8)\n",
    "                # convert np.array to Tensor[image_channels, image_height, image_width]\n",
    "                image = torch.from_numpy(temp_image).permute(2, 0, 1)\n",
    "\n",
    "            if image is not None:\n",
    "                break\n",
    "\n",
    "        boxes = self.df[self.df['img_name'] == image_name][['xmin', 'ymin', 'xmax', 'ymax']].values \n",
    "        labels = self.df[self.df['img_name'] == image_name]['label'].values\n",
    "\n",
    "        labels = torch.as_tensor(labels, dtype = torch.int64) # (n_objects)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "\n",
    "        # if xmin > xmax, flip them so width is always positive\n",
    "        if torch.any(boxes[:, 0] > boxes[:, 2]):\n",
    "            boxes[:, [0, 2]] = boxes[:, [2, 0]]\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "            \n",
    "        target = {}\n",
    "        target['boxes'] = dp.BoundingBox(boxes, format = \"XYXY\", spatial_size = (image.shape[1], image.shape[2]))\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = image_id\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        image = dp.Image(image)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet mean and std since using pretrained VGG16 backbone\n",
    "mean = [0.485, 0.456, 0.406] # 3 bands\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Same transforms as original SSD paper\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomZoomOut(fill = defaultdict(lambda: 0, {dp.Image: (255, 20, 147)}),\n",
    "                                          p = 0.3,\n",
    "                                          side_range = (1.0, 2.0)))\n",
    "        transforms.append(T.RandomIoUCrop())\n",
    "        transforms.append(T.Resize((300, 300), antialias = True)) # no maintain aspect ratio\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    else:\n",
    "        transforms.append(T.Resize((300, 300), antialias = True)) # no maintain aspect ratio\n",
    "    transforms.append(T.ToImageTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    transforms.append(T.SanitizeBoundingBox())\n",
    "    transforms.append(T.Normalize(mean, std)) # ImageNet mean and std values for normalization\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for plotting image and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are values in label_dict\n",
    "classes = list(label_dict.values())\n",
    "\n",
    "# reverse label dictionary for mapping predictions to classes\n",
    "rev_label_dict = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# distinct colors \n",
    "bbox_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: bbox_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    " \n",
    "\n",
    "def plot_bbox(ax, boxes, labels):\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    # add label text to bounding box using label_dict if label exists else labels\n",
    "    ax.text(boxes[:, 2], boxes[:, 3], \n",
    "            (label_dict[labels.item()] if labels.item() in label_dict else labels.item()),\n",
    "            fontsize = 8,\n",
    "            bbox = dict(facecolor = 'white', alpha = 0.8, pad = 0, edgecolor = 'none'),\n",
    "            color = 'black')\n",
    "\n",
    "\n",
    "# function for plotting all boxes and labels on the image using get_polygon, img_show, and plot_mask functions\n",
    "def plot_detections(image, boxes, labels, ax = None):\n",
    "    ax = img_show(image.permute(1, 2, 0), ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox(ax, box, labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot sample batch to confirm data loads and transforms correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample batch of data to custom PyTorch Dataset and Transform\n",
    "sample_dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv', \n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images', \n",
    "                                transforms = get_transform(train = True))\n",
    "\n",
    "# store image indices in random order list\n",
    "indices = torch.randperm(len(sample_dataset)).tolist()\n",
    "\n",
    "sample_data_loader = torch.utils.data.DataLoader(sample_dataset, batch_size = 8, shuffle = True, \n",
    "                                             collate_fn = utils.collate_fn, num_workers = 0)\n",
    "\n",
    "# store images and annotation targets from sample batch\n",
    "images, targets = next(iter(sample_data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "# Plot the all samples from batch in a grid of subplots. \n",
    "plt.figure(figsize = (8, 32))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(8, 2, 1 + i)\n",
    "    plot_detections(images[i], targets[i]['boxes'], targets[i]['labels'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample {i + 1}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Tune Model Hyperparameters using Ray Tune**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from datetime import datetime\n",
    "from engine import train_one_epoch, evaluate # comment out if using gradient accumulation\n",
    "# from engine_gradientAccumulation import train_one_epoch, evaluate # uncomment if using gradient accumulation\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Wrap data loaders in function and pass global data directories. \n",
    "# def load_data(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv', \n",
    "#               root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/'):\n",
    "    \n",
    "#     # use MAVdroneDataset and defined transformations\n",
    "#     dataset = MAVdroneDataset(csv_file = csv_file,\n",
    "#                                 root_dir = root_dir, \n",
    "#                                 transforms = get_transform(train = True))\n",
    "    \n",
    "#     dataset_val = MAVdroneDataset(csv_file = csv_file,\n",
    "#                                 root_dir = root_dir, \n",
    "#                                 transforms = get_transform(train = False))\n",
    "    \n",
    "#     return dataset, dataset_val\n",
    "\n",
    "# def train_MAVdroneDataset(config, indices):\n",
    "#     model = ssd300_vgg16(weights = SSD300_VGG16_Weights.DEFAULT, \n",
    "#                         weights_backbone = 'VGG16_Weights.IMAGENET1K_FEATURES')\n",
    "    \n",
    "#     device = \"cpu\" \n",
    "#     if torch.cuda.is_available():\n",
    "#         device = \"cuda:0\"\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             model = nn.DataParallel(model) # train on multiple GPUs if available\n",
    "#     model.to(device)\n",
    "\n",
    "#     # construct an optimizer \n",
    "#     params = [p for p in model.parameters() if p.requires_grad]\n",
    "#     optimizer = torch.optim.SGD(params, lr = config[\"lr\"],\n",
    "#                                 momentum = config[\"momentum\"], \n",
    "#                                 weight_decay = config[\"weight_decay\"])\n",
    "    \n",
    "#     # and a learning rate scheduler\n",
    "#     lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "#                                                    step_size = config[\"step_size\"], # period of lr decay\n",
    "#                                                    gamma = config[\"gamma\"]) # multiplicative factor of lr decay\n",
    "\n",
    "#     # Load existing checkpoint if exist.\n",
    "#     if train.get_checkpoint():\n",
    "#         loaded_checkpoint = train.get_checkpoint()\n",
    "#         with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "#             model_state, optimizer_state = torch.load(\n",
    "#                 os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "#             )\n",
    "#             model.load_state_dict(model_state)\n",
    "#             optimizer.load_state_dict(optimizer_state)\n",
    "#     else:\n",
    "#         start_epoch = 0\n",
    "\n",
    "#     dataset, dataset_val = load_data()\n",
    "\n",
    "#     # subset using a 80/15/5 split for train, validation, and test datasets\n",
    "#     dataset_train = torch.utils.data.Subset(dataset, indices[:-int(len(dataset)*0.2)]) # first 80% of dataset\n",
    "\n",
    "#     dataset_val = torch.utils.data.Subset(dataset_val, indices[-int(len(dataset)*0.2):-int(len(dataset)*0.05)]) # next 15% of dataset\n",
    "\n",
    "#     # # Uncomment if using gradient accumulation\n",
    "#     # training_steps = [\n",
    "#     #     {\"step\": 0, \"batch_size\": 16, \"epochs\": 15, \"print_freq\": 10, 'accumulation_steps': 1}, \n",
    "#     #     {\"step\": 1, \"batch_size\": 64, \"epochs\": 15, \"print_freq\": 5, 'accumulation_steps': 1},\n",
    "#     #     {\"step\": 2, \"batch_size\": 64, \"epochs\": 10, \"print_freq\": 5, 'accumulation_steps': 4}, # gpu memory maxes out at batch size 64\n",
    "#     #     {\"step\": 3, \"batch_size\": 64, \"epochs\": 5, \"print_freq\": 5, 'accumulation_steps': 16}, # batch size 1024 via gradient accumulation\n",
    "#     # ]\n",
    "\n",
    "#     # comment out if using gradient accumulation\n",
    "#     training_steps = [\n",
    "#             {\"step\": 0, \"batch_size\": 16, \"epochs\": 10, \"print_freq\": 10},\n",
    "#             {\"step\": 1, \"batch_size\": 64, \"epochs\": 5, \"print_freq\": 5}, \n",
    "#             {\"step\": 2, \"batch_size\": 256, \"epochs\": 5, \"print_freq\": 2},  \n",
    "#             {\"step\": 3, \"batch_size\": 1024, \"epochs\": 5, \"print_freq\": 1}\n",
    "#         ]\n",
    "\n",
    "#     # loop through training_steps during training to increase batch size and decrease learning rate\n",
    "#     for step in training_steps:\n",
    "#         batch_size = int(step['batch_size'])\n",
    "#         num_epochs = int(step['epochs'])\n",
    "#         print_freq = int(step['print_freq'])\n",
    "#         # accumulation_steps = int(step['accumulation_steps']) # uncomment if using gradient accumulation\n",
    "\n",
    "#         # define training and validation data loaders\n",
    "#         data_loader = torch.utils.data.DataLoader(dataset_train, batch_size = batch_size, shuffle = True, \n",
    "#                                                 collate_fn = utils.collate_fn, num_workers = 0,\n",
    "#                                                 pin_memory = True)\n",
    "        \n",
    "#         data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = 1, shuffle = False,\n",
    "#                                                     collate_fn = utils.collate_fn, num_workers = 0,\n",
    "#                                                     pin_memory = True)\n",
    "\n",
    "#         print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size}')\n",
    "\n",
    "#         for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "#             print()\n",
    "#             print(f'Epoch {epoch} beginning training...')\n",
    "#             print()\n",
    "\n",
    "#             # # uncomment if using gradient accumulation\n",
    "#             # train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, data_loader_val, accumulation_steps, device, epoch, print_freq)\n",
    "\n",
    "#             # comment out if using gradient accumulation\n",
    "#             train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, data_loader_val, device, epoch, print_freq)\n",
    "\n",
    "#             # update the learning rate\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "#             print()\n",
    "#             print(f'Epoch {epoch} preparing to evaluate the validation dataset...')\n",
    "#             print()\n",
    "            \n",
    "#             # evaluate on the val dataset\n",
    "#             train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader, data_loader_val, device)\n",
    "\n",
    "#             # Here we save a checkpoint. It is automatically registered with Ray Tune\n",
    "#             with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "#                 path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "#                 torch.save(\n",
    "#                     (model.state_dict(), optimizer.state_dict()), path\n",
    "#                 )\n",
    "#                 checkpoint = train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "#                 train.report(\n",
    "#                     {\"train_loss\": train_metric_logger.loss.global_avg, # metric_logger object\n",
    "#                     \"val_loss\": val_metric_logger.loss.global_avg,\n",
    "#                     \"train_mAP_50\": train_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "#                     \"train_mAR_100\": train_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "#                     \"val_mAP_50\": val_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "#                     \"val_mAR_100\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "#                     \"training_step\": step[\"step\"],\n",
    "#                     \"epoch\": epoch}, \n",
    "#                     checkpoint = checkpoint\n",
    "#                 )\n",
    "\n",
    "#         print(f'Training step {step[\"step\"]} complete! Moving onto training step {step[\"step\"] + 1}...')\n",
    "#         print()\n",
    "        \n",
    "#         # set start_epoch to current epoch for next training step\n",
    "#         start_epoch = num_epochs if step['step'] == 0 else num_epochs + start_epoch       \n",
    "    \n",
    "#     print('Tuning Trial Complete!')\n",
    "\n",
    "# # test set accuracy of best model\n",
    "# def test_best_model(best_result, indices):\n",
    "#     best_trained_model = ssd300_vgg16(weights = SSD300_VGG16_Weights.DEFAULT, \n",
    "#                         weights_backbone = 'VGG16_Weights.IMAGENET1K_FEATURES')\n",
    "                                      \n",
    "#     device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     best_trained_model.to(device)\n",
    "\n",
    "#     checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "#     model_state, _ = torch.load(checkpoint_path)\n",
    "#     best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "#     _, dataset_test = load_data()\n",
    "\n",
    "#     dataset_test = torch.utils.data.Subset(dataset_test, indices[-int(len(dataset_test)*0.05):]) # last 5% of dataset\n",
    "\n",
    "#     data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 1, shuffle = False,\n",
    "#                                                 collate_fn = utils.collate_fn, num_workers = 0,\n",
    "#                                                 pin_memory = True)\n",
    "    \n",
    "#     test_results = evaluate(best_trained_model, data_loader_test, device)\n",
    "\n",
    "#     print(f'Best trial test set mAP_50: {test_results.coco_eval[\"bbox\"].stats[1]} and mAR_100: {test_results.coco_eval[\"bbox\"].stats[8]}')\n",
    "\n",
    "\n",
    "# def trial_dirname_creator(trial):\n",
    "#     return f\"train_MAVdroneDataset_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Tuning Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# def main(num_samples, max_num_epochs, indices):\n",
    "#     config = {\n",
    "#         \"lr\": tune.uniform(0.0001, 0.09),\n",
    "#         \"momentum\": tune.uniform(0.3, 0.95),\n",
    "#         \"weight_decay\": tune.uniform(0.0004, 0.04),\n",
    "#         \"step_size\": tune.uniform(5, 30),\n",
    "#         \"gamma\": tune.uniform(0.2, 0.75)\n",
    "#     }\n",
    "     \n",
    "#     scheduler = ASHAScheduler(\n",
    "#         time_attr=\"epoch\",\n",
    "#         max_t=max_num_epochs,\n",
    "#         grace_period=5,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "\n",
    "#     algo = BayesOptSearch(\n",
    "#         points_to_evaluate = [\n",
    "#             {\"lr\": 0.01002, \n",
    "#              \"momentum\": 0.75711, \n",
    "#              \"weight_decay\": 0.00465, \n",
    "#              \"step_size\": 21.8483, \n",
    "#              \"gamma\": 0.39259} \n",
    "#         ], # values as starting point for search\n",
    "#         random_search_steps = 50\n",
    "#     )\n",
    "    \n",
    "#     algo = tune.search.ConcurrencyLimiter(algo, max_concurrent=1)\n",
    "\n",
    "#     tuner = tune.Tuner(\n",
    "#         tune.with_resources(\n",
    "#             tune.with_parameters(train_MAVdroneDataset, indices = indices),\n",
    "#             resources={\"cpu\": 2, \"gpu\": 1}\n",
    "#         ),\n",
    "#         run_config=train.RunConfig(\n",
    "#             storage_path='C:/Users/exx/Documents/GitHub/SSD_VGG_PyTorch/ray_results' \n",
    "#         ),\n",
    "#         tune_config=tune.TuneConfig(\n",
    "#             metric=\"val_mAP_50\",\n",
    "#             mode=\"max\",\n",
    "#             search_alg = algo,\n",
    "#             scheduler=scheduler,\n",
    "#             num_samples=num_samples,\n",
    "#             time_budget_s=600000,\n",
    "#             trial_dirname_creator=trial_dirname_creator\n",
    "#         ),\n",
    "#         param_space=config\n",
    "#     )\n",
    "\n",
    "#     results = tuner.fit()\n",
    "\n",
    "#     best_result = results.get_best_result(\"val_mAP_50\", \"max\")\n",
    "\n",
    "#     print(\"Best trial config: {}\".format(best_result.config))\n",
    "#     print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"val_loss\"]))\n",
    "#     print(\"Best trial final validation mAP_50: {}\".format(best_result.metrics[\"val_mAP_50\"]))\n",
    "#     print(\"Best trial final validation mAR_100: {}\".format(best_result.metrics[\"val_mAR_100\"]))\n",
    "\n",
    "#     test_best_model(best_result, indices)\n",
    "\n",
    "#     return best_result\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     best_trial = main(num_samples = 15, max_num_epochs = 25, indices = indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Train Model Using Tuned Hyperparameters**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# # Hyperparameters are best trial results from Bayesian Optimization using Ray Tune\n",
    "# learning_rate = best_trial.config[\"lr\"]\n",
    "# momentum = best_trial.config[\"momentum\"]\n",
    "# weight_decay = best_trial.config[\"weight_decay\"]\n",
    "# step_size = best_trial.config[\"step_size\"]\n",
    "# gamma = best_trial.config[\"gamma\"]\n",
    "\n",
    "learning_rate = 0.01002\n",
    "momentum = 0.75711 \n",
    "weight_decay = 0.00465\n",
    "step_size= 21.8483\n",
    "gamma = 0.39259\n",
    "\n",
    "# # If using gradient accumulation to overcome GPU memory limitations, set accumulation_steps to N\n",
    "# # accumulation steps is N batches to accumulate gradients for before zeroing gradients\n",
    "# training_steps = [\n",
    "#     {\"step\": 0, \"batch_size\": 16, \"lr\": learning_rate, \"epochs\": 15, \"print_freq\": 20, 'accumulation_steps': 1}, \n",
    "#     {\"step\": 1, \"batch_size\": 64, \"lr\": learning_rate, \"epochs\": 15, \"print_freq\": 5, 'accumulation_steps': 1},\n",
    "#     {\"step\": 2, \"batch_size\": 64, \"lr\": learning_rate, \"epochs\": 10, \"print_freq\": 5, 'accumulation_steps': 4}, # gpu memory maxes out at batch size 64\n",
    "#     {\"step\": 3, \"batch_size\": 64, \"lr\": learning_rate, \"epochs\": 5, \"print_freq\": 5, 'accumulation_steps': 16}, # batch size 1024 via gradient accumulation\n",
    "# ]\n",
    "\n",
    "training_steps = [\n",
    "            {\"step\": 0, \"batch_size\": 16, \"lr\": learning_rate, \"epochs\": 15, \"print_freq\": 10},\n",
    "            {\"step\": 1, \"batch_size\": 64, \"lr\": learning_rate, \"epochs\": 15, \"print_freq\": 5}, \n",
    "            {\"step\": 2, \"batch_size\": 256, \"lr\": learning_rate, \"epochs\": 10, \"print_freq\": 2}, \n",
    "            {\"step\": 3, \"batch_size\": 1024, \"lr\": learning_rate, \"epochs\": 5, \"print_freq\": 1}, \n",
    "]\n",
    "\n",
    "# Main function that performs training and validation.\n",
    "def main():\n",
    "    # Initialize model--SSD300 w/ VGG16 backbone pre-trained\n",
    "    model = ssd300_vgg16(weights = SSD300_VGG16_Weights.DEFAULT, \n",
    "                        weights_backbone = 'VGG16_Weights.IMAGENET1K_FEATURES')\n",
    "\n",
    "    device = \"cpu\" \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    # initialize tensorboard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Store one checkpoint dictionary for each epoch in a list of dictionaries. \n",
    "    checkpoints = []\n",
    "\n",
    "    # loop through training_steps during training to increase batch size and decrease learning rate\n",
    "    for step in training_steps:\n",
    "        batch_size = step['batch_size']\n",
    "        lr = step['lr']\n",
    "        num_epochs = step['epochs']\n",
    "        print_freq = step['print_freq']\n",
    "        # accumulation_steps = step['accumulation_steps']\n",
    "    \n",
    "        # use MAVdroneDataset and defined transformations\n",
    "        dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = True))\n",
    "        \n",
    "        dataset_val = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/',\n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "        # subset using a 80/15/5 split for train, validation, and test datasets\n",
    "        dataset = torch.utils.data.Subset(dataset, indices[:-int(len(dataset)*0.2)])\n",
    "\n",
    "        dataset_val = torch.utils.data.Subset(dataset_val, indices[-int(len(dataset_val)*0.2):-int(len(dataset_val)*0.05)])\n",
    "\n",
    "        # define training and validation data loaders\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, \n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                pin_memory = True)\n",
    "        \n",
    "        data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = 1, shuffle = False,\n",
    "                                                    collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                    pin_memory = True)\n",
    "        \n",
    "        # construct an optimizer - SGD w/ momentum and weight decay\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.SGD(params, lr = lr,\n",
    "                                    momentum = momentum, weight_decay = weight_decay)\n",
    "        \n",
    "        # and a learning rate scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size = step_size,\n",
    "                                                    gamma = gamma)\n",
    "        \n",
    "        # Log the hyperparameters to tensorboard\n",
    "        writer.add_hparams(\n",
    "            # {\"lr\": lr, \"momentum\": momentum, \"weight_decay\": weight_decay, \"step_size\": step_size, \"gamma\": gamma, \"batch_size\": (batch_size*accumulation_steps)}, # if using gradient accumulation\n",
    "            {\"lr\": lr, \"momentum\": momentum, \"weight_decay\": weight_decay, \"step_size\": step_size, \"gamma\": gamma, \"batch_size\": (batch_size)},\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        # print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size*accumulation_steps}')\n",
    "        print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size}')\n",
    "\n",
    "        #########################################################\n",
    "        ##               The main training loop                ##\n",
    "        #########################################################\n",
    "        for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "            print()\n",
    "            print(f'Epoch {epoch} beginning training...')\n",
    "            print()\n",
    "            \n",
    "            # # uncomment if using gradient accumulation\n",
    "            # train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, data_loader_val, accumulation_steps, device, epoch, print_freq)\n",
    "\n",
    "            # comment out if using gradient accumulation\n",
    "            train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, data_loader_val, device, epoch, print_freq)\n",
    "        \n",
    "            print()\n",
    "            print(f'Epoch {epoch} finished training!')\n",
    "            print()\n",
    "\n",
    "            # update the learning rate\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            print()\n",
    "            print(f'Epoch {epoch} preparing to calculate train and val set accuracy...')\n",
    "            print()\n",
    "            \n",
    "            # evaluate on the validation dataset\n",
    "            train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader, data_loader_val, device)\n",
    "\n",
    "            # store training and validation metrics in checkpoint dictionary. \n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_metric_logger.loss.global_avg, # metric_logger object\n",
    "                \"train_bbox_loss\": train_metric_logger.bbox_regression.global_avg,\n",
    "                \"train_class_loss\": train_metric_logger.classification.global_avg,\n",
    "                \"val_loss\": val_metric_logger.loss.global_avg,\n",
    "                \"val_bbox_loss\": val_metric_logger.bbox_regression.global_avg,\n",
    "                \"val_class_loss\": val_metric_logger.classification.global_avg,\n",
    "                \"train_mAP_50\": train_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                \"train_mAR_100\": train_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                \"val_mAP_50\": val_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                \"val_mAR_100\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "            # append checkpoint to checkpoints list\n",
    "            checkpoints.append(checkpoint)\n",
    "\n",
    "            # report training and validation scalars to tensorboard\n",
    "            writer.add_scalar('Train Loss', np.array(float(checkpoint[\"train_loss\"])), epoch)\n",
    "            writer.add_scalar('Val Loss', np.array(float(checkpoint[\"val_loss\"])), epoch)\n",
    "            writer.add_scalar('Train mAP@50', np.array(float(checkpoint[\"train_mAP_50\"])), epoch)\n",
    "            writer.add_scalar('Train mAR@100', np.array(float(checkpoint[\"train_mAR_100\"])), epoch)\n",
    "            writer.add_scalar('Val mAP@50', np.array(float(checkpoint[\"val_mAP_50\"])), epoch)\n",
    "            writer.add_scalar('Val mAR@100', np.array(float(checkpoint[\"val_mAR_100\"])), epoch)\n",
    "\n",
    "            print()\n",
    "            print(f'Epoch {epoch} complete! Moving onto epoch {epoch + 1}...')\n",
    "            print()\n",
    "        \n",
    "        print()\n",
    "        print(f'Training step {step[\"step\"]} complete! Moving onto training step {step[\"step\"] + 1}...')\n",
    "        print()\n",
    "\n",
    "        # set start_epoch to current epoch for next training step\n",
    "        start_epoch = num_epochs if step['step'] == 0 else num_epochs + start_epoch\n",
    "\n",
    "    print('All Training Steps Complete!')\n",
    "\n",
    "    # close tensorboard writer\n",
    "    writer.close()\n",
    "\n",
    "    return checkpoints\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoints = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best train epoch is dictionary in checkpoints with highest val_mAP_50 value\n",
    "best_train_epoch = max(checkpoints, key = lambda x: x['val_mAP_50'])\n",
    "\n",
    "# initialize SSD VGG16 pre-trained model\n",
    "model = ssd300_vgg16()\n",
    "\n",
    "# load model weights from best_train_epoch\n",
    "model.load_state_dict(best_train_epoch[\"model_state_dict\"])\n",
    "\n",
    "# save model weights to .pth file\n",
    "torch.save(model.state_dict(), 'SSD_VGG16_DuckNet_' + str(datetime.now().strftime(\"%m%d%Y\")) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy checkpoints and remove model and optimizer state dicts\n",
    "checkpoints_copy = checkpoints.copy()\n",
    "for dict in checkpoints_copy:\n",
    "    del dict[\"model_state_dict\"]\n",
    "    del dict[\"optimizer_state_dict\"]\n",
    "\n",
    "# save checkpoints list to text file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/checkpoints.txt', 'w') as f:\n",
    "    for item in checkpoints_copy:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Model Inference on Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indices is last 5% of indices list--not seen by model during training/validation\n",
    "test_indices = indices[-int(len(indices)*0.05):]\n",
    "\n",
    "dataset_test = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "test_image_names = [dataset_test.unique_image_names[i] for i in test_indices]\n",
    "\n",
    "# create dictionary of test indices and image names\n",
    "test_dict = dict(zip(test_indices, test_image_names))\n",
    "\n",
    "# subset test dataset using test_indices\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, test_indices)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 1, shuffle = False,\n",
    "                                            collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                            pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = evaluate(model, data_loader_test, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate performance metrics on every image in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\",\n",
    "                              class_metrics=True,\n",
    "                              max_detection_thresholds=[1, 10, 100]\n",
    "                              )\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for images, targets in data_loader_test:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    # filter targets to only include boxes and labels keys\n",
    "    ground_truth = [{k: v for k, v in t.items() if k in ('boxes', 'labels')} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # calculate mAP and mAR from test dataset\n",
    "    metric.update(prediction, ground_truth)\n",
    "    mean_AP = metric.compute()\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    mean_AP['image_name'] = test_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    results.append(mean_AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-image test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to create a dataframe of image names and mAP values\n",
    "img_results_df = pd.DataFrame()\n",
    "img_results_df['image_name'] = [result['image_name'] for result in results]\n",
    "img_results_df['mAP'] = [result['map'].item() for result in results]\n",
    "img_results_df['mAP_50'] = [result['map_50'].item() for result in results]\n",
    "img_results_df['mAP_75'] = [result['map_75'].item() for result in results]\n",
    "img_results_df['mAP_small'] = [result['map_small'].item() for result in results]\n",
    "img_results_df['mAP_medium'] = [result['map_medium'].item() for result in results]\n",
    "img_results_df['mAP_large'] = [result['map_large'].item() for result in results]\n",
    "img_results_df['mAR_1'] = [result['mar_1'].item() for result in results]\n",
    "img_results_df['mAR_10'] = [result['mar_10'].item() for result in results]\n",
    "img_results_df['mAR_100'] = [result['mar_100'].item() for result in results]\n",
    "img_results_df['mAR_small'] = [result['mar_small'].item() for result in results]\n",
    "img_results_df['mAR_medium'] = [result['mar_medium'].item() for result in results]\n",
    "img_results_df['mAR_large'] = [result['mar_large'].item() for result in results]\n",
    "\n",
    "# # if value is == -1.0, replace with NaN\n",
    "img_results_df = img_results_df.replace(-1.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric values are running averages in torch metrics, so the last value is the final value.\n",
    "final_metrics = img_results_df.iloc[-1]\n",
    "final_metrics = final_metrics.drop('image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-image metrics for test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "cols = ['Metric', 'Value']  \n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# values for column one in table are column names from final_metrics, column two are the column values. \n",
    "for i in range(len(final_metrics)):\n",
    "    x.add_row([final_metrics.index[i], f'{final_metrics[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/testDataset_image_summary_results.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "img_results_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/per_image_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-class test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_res_df = pd.DataFrame()\n",
    "\n",
    "# store 'map_per_class' and 'mar_100_per_class' from results in df\n",
    "class_res_df['image_name'] = [result['image_name'] for result in results]\n",
    "class_res_df['classes'] = [result['classes'] for result in results]\n",
    "class_res_df['map_per_class'] = [result['map_per_class'] for result in results]\n",
    "class_res_df['mar_100_per_class'] = [result['mar_100_per_class'] for result in results]\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: x.numpy())\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: x.numpy())\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: x.numpy())\n",
    "\n",
    "# replace integer labels in classes column with labels using label_dict\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: [label_dict.get(i) for i in x])\n",
    "\n",
    "# replace -1.0 values in map_per_class and mar_100_per_class with NaN\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "\n",
    "# if map_per_class or mar_100_per_class is NaN, delete value from list. Also delete corresponding class label.\n",
    "class_res_df['classes'] = class_res_df.apply(lambda x: [i for i, j in zip(x['classes'], x['map_per_class']) if not np.isnan(j)], axis = 1)\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric values are running averages in TorchMetrics. Store map and mar from last image in dataset\n",
    "classes = class_res_df['classes'].iloc[-1]\n",
    "class_map = class_res_df['map_per_class'].iloc[-1]\n",
    "class_mar_100 = class_res_df['mar_100_per_class'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-class metrics for every image in test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = 'value' and all unique classes\n",
    "cols = ['Class', 'mAP', 'mAR_100']\n",
    "\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# classes go in first column, class_map in second column, and class_mar_100 in third column\n",
    "for i in range(len(classes)):\n",
    "    x.add_row([classes[i], f'{class_map[i]*100:.2f}%', f'{class_mar_100[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/testDataset_class_summary_results.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "class_res_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/per_class_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load test data into sample batch containing some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire test dataset into one batch\n",
    "data_loader_test_all = torch.utils.data.DataLoader(dataset_test, batch_size = len(dataset_test), shuffle = False,\n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0)\n",
    "\n",
    "# run predictions on all images in the test dataset\n",
    "images, targets = next(iter(data_loader_test_all))\n",
    "\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "# convert boxes in targets to tensors\n",
    "targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images, targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post-process model predictions for plotting on original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the batch, remove all predicted boxes with scores below 0.5\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['labels'] = predictions[i]['labels'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['scores'] = predictions[i]['scores'][predictions[i]['scores'] > 0.5]\n",
    "\n",
    "# resize boxes to original image shape\n",
    "for i in range(len(images)):\n",
    "    tran_w, tran_h = images[i].shape[1], images[i].shape[2]\n",
    "    \n",
    "    images[i] = Image.open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/' + test_image_names[i])\n",
    "\n",
    "    orig_w, orig_h = images[i].size\n",
    "\n",
    "\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'] * torch.tensor([orig_w/tran_w, \n",
    "                                                                      orig_h/tran_h, \n",
    "                                                                      orig_w/tran_w,\n",
    "                                                                      orig_h/tran_h]).view(1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Plot Model Predictions for Images in Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    \n",
    "    # add label and score to the bounding box. concatenate label and score to one string. \n",
    "    # use label_dict to replace class numbers with class names\n",
    "    ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "        s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "        color = 'black',\n",
    "        fontsize = 6,\n",
    "        verticalalignment = 'top',\n",
    "        bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "    return ax\n",
    "\n",
    "\n",
    "# function for plotting all predictions on images\n",
    "def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "    ax = img_show(image, ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 32 samples from batch in a grid of subplots.\n",
    "plt.figure(figsize = (24, 36))\n",
    "for i in range(0, 32):\n",
    "    ax = plt.subplot(8, 4, 1 + i)\n",
    "    plot_predictions(images[i], predictions[i]['boxes'], predictions[i]['labels'], predictions[i]['scores'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(test_image_names[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run inference on full dataset to get model estimates of abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [dataset_all.unique_image_names[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of test indices and image names\n",
    "name_dict = dict(zip(indices, image_names))\n",
    "\n",
    "data_loader_all = torch.utils.data.DataLoader(dataset_all, batch_size = 1, shuffle = False,\n",
    "                                            collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                            pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model predictions for every image in data_loader_all\n",
    "model_predictions_all = []\n",
    "\n",
    "for images, targets in data_loader_all:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    prediction['image_name'] = name_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    model_predictions_all.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "# results = []\n",
    "# metric = MeanAveragePrecision(iou_type=\"bbox\",\n",
    "#                               class_metrics=True,\n",
    "#                               max_detection_thresholds=[1, 10, 100]\n",
    "#                               )\n",
    "# model.to('cpu')\n",
    "# model.eval()\n",
    "\n",
    "# for images, targets in data_loader_all:\n",
    "#     # use image_id to get image_name from image_names list\n",
    "#     image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "#     # convert boxes in targets to tensors\n",
    "#     targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "#     # filter targets to only include boxes and labels keys\n",
    "#     ground_truth = [{k: v for k, v in t.items() if k in ('boxes', 'labels')} for t in targets]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         prediction = model(images, targets)\n",
    "\n",
    "#     # calculate mAP and mAR from test dataset\n",
    "#     metric.update(prediction, ground_truth)\n",
    "#     mean_AP = metric.compute()\n",
    "\n",
    "#     # append image name to mean_AP\n",
    "#     mean_AP['image_name'] = name_dict[image_id[0]]\n",
    "\n",
    "#     # Append mean_AP and predictions to results list. \n",
    "#     results.append(mean_AP)\n",
    "\n",
    "# # use pandas to create a dataframe of image names and mAP values\n",
    "# results_df = pd.DataFrame()\n",
    "# results_df['image_name'] = [result['image_name'] for result in results]\n",
    "# results_df['mAP'] = [result['map'].item() for result in results]\n",
    "# results_df['mAP_50'] = [result['map_50'].item() for result in results]\n",
    "# results_df['mAP_75'] = [result['map_75'].item() for result in results]\n",
    "# results_df['mAP_small'] = [result['map_small'].item() for result in results]\n",
    "# results_df['mAP_medium'] = [result['map_medium'].item() for result in results]\n",
    "# results_df['mAP_large'] = [result['map_large'].item() for result in results]\n",
    "# results_df['mAR_1'] = [result['mar_1'].item() for result in results]\n",
    "# results_df['mAR_10'] = [result['mar_10'].item() for result in results]\n",
    "# results_df['mAR_100'] = [result['mar_100'].item() for result in results]\n",
    "# results_df['mAR_small'] = [result['mar_small'].item() for result in results]\n",
    "# results_df['mAR_medium'] = [result['mar_medium'].item() for result in results]\n",
    "# results_df['mAR_large'] = [result['mar_large'].item() for result in results]\n",
    "\n",
    "# # if value is == -1.0, replace with NaN\n",
    "# results_df = results_df.replace(-1.0, np.nan)\n",
    "\n",
    "# # save results_df to csv\n",
    "# results_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/all_image_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_res_df = pd.DataFrame()\n",
    "\n",
    "# # store 'map_per_class' and 'mar_100_per_class' from results in df\n",
    "# class_res_df['image_name'] = [result['image_name'] for result in results]\n",
    "# class_res_df['classes'] = [result['classes'] for result in results]\n",
    "# class_res_df['map_per_class'] = [result['map_per_class'] for result in results]\n",
    "# class_res_df['mar_100_per_class'] = [result['mar_100_per_class'] for result in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSD_PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
