{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Reading and Cleaning Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion(); # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for processing JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading JSON as dictionary\n",
    "def read_json(filename: str) -> dict:\n",
    "  \n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.loads(f.read())\n",
    "    except:\n",
    "        raise Exception(f\"Reading {filename} file encountered an error\")\n",
    "  \n",
    "    return data\n",
    "\n",
    "# Function to append records to df\n",
    "def create_dataframe(data: list) -> pd.DataFrame:\n",
    "\n",
    "    # Create an empty dataframe to append records\n",
    "    df = pd.DataFrame()\n",
    "  \n",
    "    # Looping through each record\n",
    "    for d in data:\n",
    "          \n",
    "        # Normalize the column levels\n",
    "        record = pd.json_normalize(d)\n",
    "\n",
    "        df = pd.concat([df, record], axis=0)\n",
    "          \n",
    "    return df\n",
    "\n",
    "# Main function to iterate over files in directory and add to df\n",
    "def main():\n",
    "    # Assign directory and empty df for appending annotations\n",
    "    directory = \"C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Annotations/\" # annotation directory\n",
    "    annos_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over files in directory\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            print(f)\n",
    "            \n",
    "        # Read the JSON file as python dictionary \n",
    "        data = read_json(filename = f)\n",
    "    \n",
    "        # Create the dataframe for the array items in annotations key \n",
    "        df = create_dataframe(data = data['annotations'])\n",
    "        df.insert(loc = 0, column = 'img_name', value = f'{f[-30:-5]}.JPG')\n",
    "    \n",
    "        df.rename(columns = {\n",
    "            \"img_name\": \"img_name\",\n",
    "            \"name\": \"label\",\n",
    "            \"bounding_box.h\": \"bbox_height\",\n",
    "            \"bounding_box.w\": \"bbox_width\",\n",
    "            \"bounding_box.x\": \"bbox_x_topLeft\",\n",
    "            \"bounding_box.y\": \"bbox_y_topLeft\",\n",
    "            \"polygon.paths\": \"polygon_path\"\n",
    "        }, inplace = True)\n",
    "        \n",
    "        # Append the df dataframe to the annos_df dataframe\n",
    "        annos_df = pd.concat([annos_df, df], ignore_index=True)\n",
    "\n",
    "    # Convert x, y, h, w to xmin, ymin, xmax, ymax\n",
    "    annos_df.insert(loc = 2, column = 'xmin', \n",
    "                    value = annos_df['bbox_x_topLeft'])\n",
    "    annos_df.insert(loc = 3, column = 'ymin', \n",
    "                    value = annos_df['bbox_y_topLeft'])\n",
    "    annos_df.insert(loc = 4, column = 'xmax', \n",
    "                    value = annos_df['bbox_x_topLeft'] + annos_df['bbox_width'])\n",
    "    annos_df.insert(loc = 5, column = 'ymax', \n",
    "                    value = annos_df['bbox_y_topLeft'] + annos_df['bbox_height']) \n",
    "  \n",
    "    # Drop unneccessary columns \n",
    "    annos_df = annos_df.drop(columns = ['bbox_height', 'bbox_width', 'bbox_x_topLeft', \n",
    "                                        'bbox_y_topLeft', 'id', 'slot_names', 'polygon_path'])\n",
    "        \n",
    "    return annos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load annotation data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main loading function\n",
    "if __name__ == '__main__':\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter annotation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If label value count is less than 200, drop the row\n",
    "df = df.groupby('label').filter(lambda x : len(x) > 200)\n",
    "\n",
    "# If label value is 'Hen', drop the row\n",
    "df = df[df['label'] != 'Hen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter images since most annotation class were filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store unique img_names in filtered df as array\n",
    "img_names = df['img_name'].unique().tolist()\n",
    "\n",
    "# Create a new directory called 'filtered_images'\n",
    "new_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images'\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# Copy images in img_names to new directory\n",
    "for img in img_names:\n",
    "    shutil.copy2(f'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/Images/{img}', new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Transform and Augment Image and Annotation Data for Custom PyTorch Object Detection**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "cudnn.benchmark = True\n",
    "from torchvision import transforms as _transforms, tv_tensors\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-process annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical data and get the numeric codes\n",
    "df['target'] = pd.Categorical(df['label']).codes + 1\n",
    "\n",
    "# Create a dictionary using df['label'] as the keys and df['target'] as the values\n",
    "label_dict = dict(zip(df['target'], df['label']))\n",
    "\n",
    "# Drop the original 'label' column from df\n",
    "df = df.drop(['label'], axis=1)\n",
    "\n",
    "# Rename 'target' column to 'label'\n",
    "df.rename(columns={'target': 'label'}, inplace=True)\n",
    "\n",
    "# Save df as csv in directory\n",
    "df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch dataset for custom image and annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset loader (PyTorch) for loading images and annotation data\n",
    "class MAVdroneDataset(Dataset):\n",
    "    \"\"\"Dataset Loader for Waterfowl Drone Imagery\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transforms):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            root_dir (string): Directory containing all images.\n",
    "            transforms (string): train = True for training transforms\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.unique_image_names = self.df['img_name'].unique()\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_name = self.unique_image_names[idx]\n",
    "\n",
    "        # isolate first row prevents multiple instances of the same image\n",
    "        row = self.df[self.df['img_name'] == image_name].iloc[0]\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, row['img_name'])\n",
    "        image = None\n",
    "\n",
    "        # ignore corrupted image data during loading else error\n",
    "        while True:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                buff = BytesIO()\n",
    "                buff.write(f.read())\n",
    "                buff.seek(0)\n",
    "                temp_image = np.array(Image.open(buff), dtype = np.uint8)\n",
    "                # convert np.array to Tensor[image_channels, image_height, image_width]\n",
    "                image = torch.from_numpy(temp_image).permute(2, 0, 1)\n",
    "\n",
    "            if image is not None:\n",
    "                break\n",
    "\n",
    "        boxes = self.df[self.df['img_name'] == image_name][['xmin', 'ymin', 'xmax', 'ymax']].values \n",
    "        labels = self.df[self.df['img_name'] == image_name]['label'].values\n",
    "\n",
    "        labels = torch.as_tensor(labels, dtype = torch.int64) # (n_objects)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "\n",
    "        # if xmin > xmax, flip them so width is always positive\n",
    "        if torch.any(boxes[:, 0] > boxes[:, 2]):\n",
    "            boxes[:, [0, 2]] = boxes[:, [2, 0]]\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
    "            \n",
    "        target = {}\n",
    "        target['boxes'] = tv_tensors.BoundingBoxes(boxes, format = tv_tensors.BoundingBoxFormat.XYXY, canvas_size = (image.shape[1], image.shape[2]))\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = image_id\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        image = tv_tensors.Image(image)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet mean and std since using pretrained ResNet backbone\n",
    "mean = [0.485, 0.456, 0.406] # 3 bands\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Same transforms as original SSD paper\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomZoomOut(fill = defaultdict(lambda: 0, {tv_tensors.Image: (255, 20, 147)}),\n",
    "                                          p = 0.3,\n",
    "                                          side_range = (1.0, 2.0)))\n",
    "        transforms.append(T.RandomIoUCrop())\n",
    "        transforms.append(T.Resize((512, 512), antialias = True)) # no maintain aspect ratio\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    else:\n",
    "        transforms.append(T.Resize((512, 512), antialias = True)) # no maintain aspect ratio\n",
    "    transforms.append(T.ToImage())\n",
    "    transforms.append(T.ToDtype(torch.float32, scale=True))\n",
    "    transforms.append(T.SanitizeBoundingBoxes())\n",
    "    transforms.append(T.Normalize(mean, std)) # ImageNet mean and std values for normalization\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for plotting image and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are values in label_dict\n",
    "classes = list(label_dict.values())\n",
    "\n",
    "# reverse label dictionary for mapping predictions to classes\n",
    "rev_label_dict = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# distinct colors \n",
    "bbox_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: bbox_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    " \n",
    "\n",
    "def plot_bbox(ax, boxes, labels):\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    # add label text to bounding box using label_dict if label exists else labels\n",
    "    ax.text(boxes[:, 2], boxes[:, 3], \n",
    "            (label_dict[labels.item()] if labels.item() in label_dict else labels.item()),\n",
    "            fontsize = 8,\n",
    "            bbox = dict(facecolor = 'white', alpha = 0.8, pad = 0, edgecolor = 'none'),\n",
    "            color = 'black')\n",
    "\n",
    "\n",
    "# function for plotting all boxes and labels on the image using get_polygon, img_show, and plot_mask functions\n",
    "def plot_detections(image, boxes, labels, ax = None):\n",
    "    ax = img_show(image.permute(1, 2, 0), ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox(ax, box, labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot sample batch to confirm data loads and transforms correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample batch of data to custom PyTorch Dataset and Transform\n",
    "sample_dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv', \n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images', \n",
    "                                transforms = get_transform(train = True))\n",
    "\n",
    "# store image indices in random order list\n",
    "indices = torch.randperm(len(sample_dataset)).tolist()\n",
    "\n",
    "sample_data_loader = torch.utils.data.DataLoader(sample_dataset, batch_size = 8, shuffle = True, \n",
    "                                             collate_fn = utils.collate_fn, num_workers = 0)\n",
    "\n",
    "# store images and annotation targets from sample batch\n",
    "images, targets = next(iter(sample_data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "# Plot the all samples from batch in a grid of subplots. \n",
    "plt.figure(figsize = (8, 32))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(8, 2, 1 + i)\n",
    "    plot_detections(images[i], targets[i]['boxes'], targets[i]['labels'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample {i + 1}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for loading RetinaNet with custom num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retinanet_model(num_classes):\n",
    "    # Load the pre-trained model\n",
    "    model = retinanet_resnet50_fpn_v2(weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT,\n",
    "                                    weights_backbone=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # Replace the classification head's cls_logits layer with a new one\n",
    "    in_channels = model.head.classification_head.cls_logits.in_channels\n",
    "    model.head.classification_head.cls_logits = nn.Conv2d(in_channels, num_classes * model.head.classification_head.num_anchors, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    # Update the number of classes in the model\n",
    "    model.head.classification_head.num_classes = num_classes\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Tune Model Hyperparameters using Ray Tune**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from engine import train_one_epoch, evaluate \n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MAVdroneDataset(config, indices):\n",
    "    # get dataset train and dataloader val from ray object store\n",
    "    dataset_train = ray.get(config[\"dataset_train_ref\"])\n",
    "    data_loader_val = ray.get(config[\"data_loader_val_ref\"])\n",
    "    \n",
    "    # construct custom retinanet model\n",
    "    model = get_retinanet_model(num_classes=len(classes) + 1) # add 1 for background class\n",
    "    device = \"cpu\" \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model) # train on multiple GPUs if available\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr = config[\"lr\"],\n",
    "                                momentum = config[\"momentum\"], \n",
    "                                weight_decay = config[\"weight_decay\"])\n",
    "    \n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size = config[\"step_size\"], # period of lr decay\n",
    "                                                   gamma = config[\"gamma\"]) # multiplicative factor of lr decay\n",
    "\n",
    "    # Load existing checkpoint if exist.\n",
    "    if train.get_checkpoint():\n",
    "        loaded_checkpoint = train.get_checkpoint()\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "            )\n",
    "            model.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    training_steps = [\n",
    "            {\"step\": 0, \"batch_size\": config[\"batch_size\"], \"epochs\": 10, \"print_freq\": 10},\n",
    "            {\"step\": 1, \"batch_size\": config[\"batch_size\"]*4, \"epochs\": 10, \"print_freq\": 5}, \n",
    "            {\"step\": 2, \"batch_size\": config[\"batch_size\"]*4**2, \"epochs\": 10, \"print_freq\": 2},  \n",
    "            {\"step\": 3, \"batch_size\": config[\"batch_size\"]*4**3, \"epochs\": 10, \"print_freq\": 1}\n",
    "        ]\n",
    "\n",
    "    # loop through training_steps during training to increase batch size and decrease learning rate\n",
    "    for step in training_steps:\n",
    "        batch_size = int(step['batch_size'])\n",
    "        num_epochs = int(step['epochs'])\n",
    "        print_freq = int(step['print_freq'])\n",
    "\n",
    "        # define training and validation data loaders\n",
    "        data_loader = torch.utils.data.DataLoader(dataset_train, batch_size = batch_size, shuffle = True, \n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                pin_memory = True)\n",
    "    \n",
    "        print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size}')\n",
    "\n",
    "        for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "            train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, data_loader_val)\n",
    "\n",
    "            # update the learning rate\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            # evaluate on the val dataset\n",
    "            train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader_val, device, data_loader)\n",
    "\n",
    "            # Here we save a checkpoint. It is automatically registered with Ray Tune\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "                torch.save(\n",
    "                    (model.state_dict(), optimizer.state_dict()), path\n",
    "                )\n",
    "                checkpoint = train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "                train.report(\n",
    "                    {\"train_loss\": train_metric_logger.loss.avg, # metric_logger object\n",
    "                    \"val_loss\": val_metric_logger.loss.avg,\n",
    "                    \"train_mAP_50\": train_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                    \"val_mAP_50\": val_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                    \"train_mAR_100\": train_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                    \"val_mAR_100\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                    \"training_step\": step[\"step\"],\n",
    "                    \"epoch\": epoch}, \n",
    "                    checkpoint = checkpoint\n",
    "                )\n",
    "        \n",
    "        # set start_epoch to current epoch for next training step\n",
    "        start_epoch = num_epochs if step['step'] == 0 else num_epochs + start_epoch       \n",
    "    \n",
    "    print('Tuning Trial Complete!')\n",
    "\n",
    "# test set accuracy of best model\n",
    "def test_best_model(best_result, indices):\n",
    "    best_model =  get_retinanet_model(num_classes=len(classes) + 1) # add 1 for background class\n",
    "                                      \n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    best_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    model_state, _ = torch.load(checkpoint_path)\n",
    "    best_model.load_state_dict(model_state)\n",
    "\n",
    "    dataset_test = ray.get(best_result.config[\"dataset_test_ref\"]) # loads dataset without augmentations from ray object store\n",
    "\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, indices[-int(len(dataset_test)*0.05):]) # last 5% of dataset\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 1, shuffle = False,\n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                pin_memory = True)\n",
    "    \n",
    "    test_results = evaluate(best_model, data_loader_test, device, train_data_loader=None)\n",
    "\n",
    "    print(f'Best trial test set mAP_50: {test_results.coco_eval[\"bbox\"].stats[1]} and mAR_100: {test_results.coco_eval[\"bbox\"].stats[8]}')\n",
    "\n",
    "def trial_dirname_creator(trial):\n",
    "    return f\"train_MAVdroneDataset_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Tuning Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_MAVdroneDataset pid=60080)\u001b[0m Epoch: [0] Training  [ 70/375]  eta: 0:06:16  lr: 0.000953  loss: 6.1857 (128.9551)  classification: 5.9321 (128.6743)  bbox_regression: 0.2537 (0.2808)  time: 1.2529  data: 1.0898  max mem: 3949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 20:24:05,690\tINFO tune.py:1041 -- Total run time: 101.50 seconds (91.40 seconds for the tuning loop).\n",
      "2024-11-04 20:24:05,690\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"C:/Users/exx/Documents/GitHub/SSD_VGG_PyTorch/ray_results/train_MAVdroneDataset_RetinaNet\", trainable=...)\n",
      "2024-11-04 20:24:05,690\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_mAP_50. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_trial, test_performance\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 99\u001b[0m     best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 84\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(num_samples, max_num_epochs, indices)\u001b[0m\n\u001b[0;32m     60\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[0;32m     61\u001b[0m     tune\u001b[38;5;241m.\u001b[39mwith_resources(\n\u001b[0;32m     62\u001b[0m         tune\u001b[38;5;241m.\u001b[39mwith_parameters(train_MAVdroneDataset, indices \u001b[38;5;241m=\u001b[39m indices),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     param_space\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m---> 84\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_mAP_50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mconfig))\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final training loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\exx\\.conda\\envs\\bohb\\lib\\site-packages\\ray\\tune\\result_grid.py:161\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[1;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[0;32m    150\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_mAP_50. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def main(num_samples, max_num_epochs, indices):\n",
    "\n",
    "    dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                            root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                            transforms = get_transform(train = True))\n",
    "\n",
    "    dataset_val = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                            root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                            transforms = get_transform(train = False))\n",
    "    \n",
    "    dataset_test_ref = ray.put(dataset_val) # same (no augmentations) as val ds before subsetting\n",
    "    \n",
    "    # subset using a 80/15/5 split for train, validation, and test datasets\n",
    "    dataset_train = torch.utils.data.Subset(dataset, indices[:-int(len(indices)*0.2)]) # first 80% of dataset\n",
    "\n",
    "    dataset_val = torch.utils.data.Subset(dataset_val, indices[-int(len(indices)*0.2):-int(len(indices)*0.05)]) # next 15% of dataset\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = 1, shuffle = False,\n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                pin_memory = True)\n",
    "    \n",
    "    dataset_train_ref = ray.put(dataset_train)\n",
    "    data_loader_val_ref = ray.put(data_loader_val)\n",
    "    \n",
    "    config = {\n",
    "        \"lr\": tune.uniform(0.0001, 0.09),\n",
    "        \"momentum\": tune.uniform(0.3, 0.95),\n",
    "        \"weight_decay\": tune.uniform(0.00005, 0.05),\n",
    "        \"step_size\": tune.uniform(1, 10),\n",
    "        \"gamma\": tune.uniform(0.05, 0.9),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16]),\n",
    "        \"dataset_train_ref\": dataset_train_ref,\n",
    "        \"data_loader_val_ref\": data_loader_val_ref,\n",
    "        \"dataset_test_ref\": dataset_test_ref\n",
    "    }\n",
    "\n",
    "    algo = TuneBOHB(\n",
    "        metric=\"val_mAP_50\",\n",
    "        mode=\"max\",\n",
    "        points_to_evaluate = [\n",
    "            {\"lr\": 0.005, \n",
    "             \"momentum\": 0.9, \n",
    "             \"weight_decay\": 0.0005, \n",
    "             \"step_size\": 3, \n",
    "             \"gamma\": 0.1,\n",
    "             \"batch_size\": 4} \n",
    "        ] # PyTorch default values as starting point for search\n",
    "    )\n",
    "    algo = tune.search.ConcurrencyLimiter(algo, max_concurrent=2)\n",
    "    scheduler = HyperBandForBOHB(\n",
    "        time_attr=\"training_iteration\",\n",
    "        max_t=int(max_num_epochs),\n",
    "        reduction_factor=4,\n",
    "        stop_last_trials=False,\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_MAVdroneDataset, indices = indices),\n",
    "            resources={\"cpu\": 24.0, \"gpu\": 0.5}\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            name=\"train_MAVdroneDataset_RetinaNet\",\n",
    "            storage_path='C:/Users/exx/Documents/GitHub/SSD_VGG_PyTorch/ray_results',\n",
    "            stop={\"training_iteration\": max_num_epochs},\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_mAP_50\",\n",
    "            mode=\"max\",\n",
    "            search_alg = algo,\n",
    "            scheduler=scheduler,\n",
    "            num_samples=int(num_samples),\n",
    "            time_budget_s=600000,\n",
    "            trial_dirname_creator=trial_dirname_creator\n",
    "        ),\n",
    "        param_space=config\n",
    "    )\n",
    "\n",
    "    results = tuner.fit()\n",
    "\n",
    "    best_trial = results.get_best_result(\"val_mAP_50\", \"max\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final training loss: {}\".format(best_trial.metrics[\"train_loss\"]))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.metrics[\"val_loss\"]))\n",
    "    print(\"Best trial final training mAP_50: {}\".format(best_trial.metrics[\"train_mAP_50\"]))\n",
    "    print(\"Best trial final validation mAP_50: {}\".format(best_trial.metrics[\"val_mAP_50\"]))\n",
    "    print(\"Best trial final training mAR_100: {}\".format(best_trial.metrics[\"train_mAR_100\"]))\n",
    "    print(\"Best trial final validation mAR_100: {}\".format(best_trial.metrics[\"val_mAR_100\"]))\n",
    "\n",
    "    test_performance = test_best_model(best_trial, indices)\n",
    "\n",
    "    return best_trial, test_performance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_trial = main(num_samples = 30, max_num_epochs = 45, indices = indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Train Model Using Tuned Hyperparameters**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Hyperparameters are best trial results from Bayesian Optimization using Ray Tune\n",
    "learning_rate = best_trial.config[\"lr\"]\n",
    "momentum = best_trial.config[\"momentum\"]\n",
    "weight_decay = best_trial.config[\"weight_decay\"]\n",
    "step_size = best_trial.config[\"step_size\"]\n",
    "gamma = best_trial.config[\"gamma\"]\n",
    "batch_size = best_trial.config[\"batch_size\"]\n",
    "\n",
    "training_steps = [\n",
    "            {\"step\": 0, \"batch_size\": batch_size, \"epochs\": 10, \"print_freq\": 10},\n",
    "            {\"step\": 1, \"batch_size\": batch_size*4, \"epochs\": 10, \"print_freq\": 5}, \n",
    "            {\"step\": 2, \"batch_size\": batch_size*4**2, \"epochs\": 10, \"print_freq\": 2},  \n",
    "            {\"step\": 3, \"batch_size\": batch_size*4**3, \"epochs\": 10, \"print_freq\": 1}\n",
    "        ]\n",
    "\n",
    "# Main function that performs training and validation.\n",
    "def main():\n",
    "    # Initialize model--SSD300 w/ VGG16 backbone pre-trained\n",
    "    model = get_retinanet_model(num_classes=len(classes) + 1) # add 1 for background class\n",
    "\n",
    "    device = \"cpu\" \n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    # initialize tensorboard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Store one checkpoint dictionary for each epoch in a list of dictionaries. \n",
    "    checkpoints = []\n",
    "\n",
    "    # loop through training_steps during training to increase batch size and decrease learning rate\n",
    "    for step in training_steps:\n",
    "        batch_size = step['batch_size']\n",
    "        num_epochs = step['epochs']\n",
    "        print_freq = step['print_freq']\n",
    "        batch_size = step['batch_size']\n",
    "    \n",
    "        # use MAVdroneDataset and defined transformations\n",
    "        dataset = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = True))\n",
    "        \n",
    "        dataset_val = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/',\n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "        # subset using a 80/15/5 split for train, validation, and test datasets\n",
    "        dataset = torch.utils.data.Subset(dataset, indices[:-int(len(dataset)*0.2)])\n",
    "\n",
    "        dataset_val = torch.utils.data.Subset(dataset_val, indices[-int(len(dataset_val)*0.2):-int(len(dataset_val)*0.05)])\n",
    "\n",
    "        # define training and validation data loaders\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, \n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                pin_memory = True)\n",
    "        \n",
    "        data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_size = 1, shuffle = False,\n",
    "                                                    collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                                    pin_memory = True)\n",
    "        \n",
    "        # construct an optimizer - SGD w/ momentum and weight decay\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.SGD(params, lr = learning_rate,\n",
    "                                    momentum = momentum, weight_decay = weight_decay)\n",
    "        \n",
    "        # and a learning rate scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size = step_size,\n",
    "                                                    gamma = gamma)\n",
    "        \n",
    "        # Log the hyperparameters to tensorboard\n",
    "        writer.add_hparams(\n",
    "            {\"lr\": learning_rate, \"momentum\": momentum, \"weight_decay\": weight_decay, \"step_size\": step_size, \"gamma\": gamma, \"batch_size\": (batch_size)},\n",
    "            {}\n",
    "        )\n",
    "        \n",
    "        print(f'Beginning training step {step[\"step\"]}... batch size: {batch_size}')\n",
    "\n",
    "        #########################################################\n",
    "        ##               The main training loop                ##\n",
    "        #########################################################\n",
    "        for epoch in range(start_epoch, num_epochs + start_epoch):\n",
    "            print()\n",
    "            print(f'Epoch {epoch} beginning training...')\n",
    "            print()\n",
    "\n",
    "            train_metric_logger, val_metric_logger = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, data_loader_val)\n",
    "        \n",
    "            print()\n",
    "            print(f'Epoch {epoch} finished training!')\n",
    "            print()\n",
    "\n",
    "            # update the learning rate\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            print()\n",
    "            print(f'Epoch {epoch} preparing to calculate train and val set accuracy...')\n",
    "            print()\n",
    "            \n",
    "            # evaluate on the validation dataset\n",
    "            train_coco_evaluator, val_coco_evaluator = evaluate(model, data_loader_val, device, data_loader)\n",
    "\n",
    "            # store training and validation metrics in checkpoint dictionary. \n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_metric_logger.loss.avg, # average across entire trianing epoch\n",
    "                \"train_bbox_loss\": train_metric_logger.bbox_regression.avg,\n",
    "                \"train_class_loss\": train_metric_logger.classification.avg,\n",
    "                \"val_loss\": val_metric_logger.loss.avg,\n",
    "                \"val_bbox_loss\": val_metric_logger.bbox_regression.avg,\n",
    "                \"val_class_loss\": val_metric_logger.classification.avg,\n",
    "                \"train_mAP_50\": train_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                \"train_mAR_100\": train_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                \"val_mAP_50\": val_coco_evaluator.coco_eval['bbox'].stats[1],\n",
    "                \"val_mAR_100\": val_coco_evaluator.coco_eval['bbox'].stats[8],\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "            # append checkpoint to checkpoints list\n",
    "            checkpoints.append(checkpoint)\n",
    "\n",
    "            # report training and validation scalars to tensorboard\n",
    "            writer.add_scalar('Train Loss', np.array(float(checkpoint[\"train_loss\"])), epoch)\n",
    "            writer.add_scalar('Val Loss', np.array(float(checkpoint[\"val_loss\"])), epoch)\n",
    "            writer.add_scalar('Train mAP@50', np.array(float(checkpoint[\"train_mAP_50\"])), epoch)\n",
    "            writer.add_scalar('Train mAR@100', np.array(float(checkpoint[\"train_mAR_100\"])), epoch)\n",
    "            writer.add_scalar('Val mAP@50', np.array(float(checkpoint[\"val_mAP_50\"])), epoch)\n",
    "            writer.add_scalar('Val mAR@100', np.array(float(checkpoint[\"val_mAR_100\"])), epoch)\n",
    "\n",
    "            print()\n",
    "            print(f'Epoch {epoch} complete! Moving onto epoch {epoch + 1}...')\n",
    "            print()\n",
    "        \n",
    "        print()\n",
    "        print(f'Training step {step[\"step\"]} complete! Moving onto training step {step[\"step\"] + 1}...')\n",
    "        print()\n",
    "\n",
    "        # set start_epoch to current epoch for next training step\n",
    "        start_epoch = num_epochs if step['step'] == 0 else num_epochs + start_epoch\n",
    "\n",
    "    print('All Training Steps Complete!')\n",
    "\n",
    "    # close tensorboard writer\n",
    "    writer.close()\n",
    "\n",
    "    return checkpoints\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoints = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best train epoch is dictionary in checkpoints with highest val_mAP_50 value\n",
    "best_train_epoch = max(checkpoints, key = lambda x: x['val_mAP_50'])\n",
    "\n",
    "model = get_retinanet_model(num_classes=len(classes) + 1) # add 1 for background class\n",
    "\n",
    "# load model weights from best_train_epoch\n",
    "model.load_state_dict(best_train_epoch[\"model_state_dict\"])\n",
    "\n",
    "# save model weights to .pth file\n",
    "torch.save(model.state_dict(), 'RetinaNet_ResNet50_FPN_DuckNet_' + str(datetime.now().strftime(\"%m%d%Y\")) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy checkpoints and remove model and optimizer state dicts\n",
    "checkpoints_copy = checkpoints.copy()\n",
    "for c in checkpoints_copy:\n",
    "    del c[\"model_state_dict\"]\n",
    "    del c[\"optimizer_state_dict\"]\n",
    "\n",
    "# save checkpoints list to text file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/RetinaNet/checkpoints.txt', 'w') as f:\n",
    "    for item in checkpoints_copy:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Model Inference on Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indices is last 5% of indices list--not seen by model during training/validation\n",
    "test_indices = indices[-int(len(indices)*0.05):]\n",
    "\n",
    "dataset_test = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = False))\n",
    "\n",
    "test_image_names = [dataset_test.unique_image_names[i] for i in test_indices]\n",
    "\n",
    "# create dictionary of test indices and image names\n",
    "test_dict = dict(zip(test_indices, test_image_names))\n",
    "\n",
    "# subset test dataset using test_indices\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, test_indices)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 1, shuffle = False,\n",
    "                                            collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                            pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = evaluate(model, data_loader_test, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate performance metrics on every image in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\",\n",
    "                              class_metrics=True,\n",
    "                              max_detection_thresholds=[1, 10, 100]\n",
    "                              )\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "for images, targets in data_loader_test:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    # filter targets to only include boxes and labels keys\n",
    "    ground_truth = [{k: v for k, v in t.items() if k in ('boxes', 'labels')} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # calculate mAP and mAR from test dataset\n",
    "    metric.update(prediction, ground_truth)\n",
    "    mean_AP = metric.compute()\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    mean_AP['image_name'] = test_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    results.append(mean_AP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-image test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to create a dataframe of image names and mAP values\n",
    "img_results_df = pd.DataFrame()\n",
    "img_results_df['image_name'] = [result['image_name'] for result in results]\n",
    "img_results_df['mAP'] = [result['map'].item() for result in results]\n",
    "img_results_df['mAP_50'] = [result['map_50'].item() for result in results]\n",
    "img_results_df['mAP_75'] = [result['map_75'].item() for result in results]\n",
    "img_results_df['mAP_small'] = [result['map_small'].item() for result in results]\n",
    "img_results_df['mAP_medium'] = [result['map_medium'].item() for result in results]\n",
    "img_results_df['mAP_large'] = [result['map_large'].item() for result in results]\n",
    "img_results_df['mAR_1'] = [result['mar_1'].item() for result in results]\n",
    "img_results_df['mAR_10'] = [result['mar_10'].item() for result in results]\n",
    "img_results_df['mAR_100'] = [result['mar_100'].item() for result in results]\n",
    "img_results_df['mAR_small'] = [result['mar_small'].item() for result in results]\n",
    "img_results_df['mAR_medium'] = [result['mar_medium'].item() for result in results]\n",
    "img_results_df['mAR_large'] = [result['mar_large'].item() for result in results]\n",
    "\n",
    "# # if value is == -1.0, replace with NaN\n",
    "img_results_df = img_results_df.replace(-1.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric values are running averages in torch metrics, so the last value is the final value.\n",
    "final_metrics = img_results_df.iloc[-1]\n",
    "final_metrics = final_metrics.drop('image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-image metrics for test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "cols = ['Metric', 'Value']  \n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# values for column one in table are column names from final_metrics, column two are the column values. \n",
    "for i in range(len(final_metrics)):\n",
    "    x.add_row([final_metrics.index[i], f'{final_metrics[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/testDataset_image_summary_results.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "img_results_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/per_image_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store per-class test dataset metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_res_df = pd.DataFrame()\n",
    "\n",
    "# store 'map_per_class' and 'mar_100_per_class' from results in df\n",
    "class_res_df['image_name'] = [result['image_name'] for result in results]\n",
    "class_res_df['classes'] = [result['classes'] for result in results]\n",
    "class_res_df['map_per_class'] = [result['map_per_class'] for result in results]\n",
    "class_res_df['mar_100_per_class'] = [result['mar_100_per_class'] for result in results]\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: x.numpy())\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: x.numpy())\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: x.numpy())\n",
    "\n",
    "# replace integer labels in classes column with labels using label_dict\n",
    "class_res_df['classes'] = class_res_df['classes'].apply(lambda x: [label_dict.get(i) for i in x])\n",
    "\n",
    "# replace -1.0 values in map_per_class and mar_100_per_class with NaN\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: np.where(x == -1.0, np.nan, x))\n",
    "\n",
    "# if map_per_class or mar_100_per_class is NaN, delete value from list. Also delete corresponding class label.\n",
    "class_res_df['classes'] = class_res_df.apply(lambda x: [i for i, j in zip(x['classes'], x['map_per_class']) if not np.isnan(j)], axis = 1)\n",
    "class_res_df['map_per_class'] = class_res_df['map_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])\n",
    "class_res_df['mar_100_per_class'] = class_res_df['mar_100_per_class'].apply(lambda x: [i for i in x if not np.isnan(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric values are running averages in TorchMetrics. Store map and mar from last image in dataset\n",
    "classes = class_res_df['classes'].iloc[-1]\n",
    "class_map = class_res_df['map_per_class'].iloc[-1]\n",
    "class_mar_100 = class_res_df['mar_100_per_class'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print per-class metrics for every image in test dataset as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = 'value' and all unique classes\n",
    "cols = ['Class', 'mAP', 'mAR_100']\n",
    "\n",
    "# create a pretty table object\n",
    "x = PrettyTable()\n",
    "\n",
    "# add column headers\n",
    "x.field_names = cols\n",
    "\n",
    "# classes go in first column, class_map in second column, and class_mar_100 in third column\n",
    "for i in range(len(classes)):\n",
    "    x.add_row([classes[i], f'{class_map[i]*100:.2f}%', f'{class_mar_100[i]*100:.2f}%'])\n",
    "\n",
    "# print table\n",
    "print(x)\n",
    "\n",
    "# save table as txt file\n",
    "with open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/testDataset_class_summary_results.txt', 'w') as f:\n",
    "    print(x, file = f)\n",
    "\n",
    "# save results_df to csv\n",
    "class_res_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/per_class_results_test_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load test data into sample batch containing some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire test dataset into one batch\n",
    "data_loader_test_all = torch.utils.data.DataLoader(dataset_test, batch_size = len(dataset_test), shuffle = False,\n",
    "                                                collate_fn = utils.collate_fn, num_workers = 0)\n",
    "\n",
    "# run predictions on all images in the test dataset\n",
    "images, targets = next(iter(data_loader_test_all))\n",
    "\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "# convert boxes in targets to tensors\n",
    "targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images, targets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post-process model predictions for plotting on original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the batch, remove all predicted boxes with scores below 0.5\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['labels'] = predictions[i]['labels'][predictions[i]['scores'] > 0.5]\n",
    "    predictions[i]['scores'] = predictions[i]['scores'][predictions[i]['scores'] > 0.5]\n",
    "\n",
    "# resize boxes to original image shape\n",
    "for i in range(len(images)):\n",
    "    tran_w, tran_h = images[i].shape[1], images[i].shape[2]\n",
    "    \n",
    "    images[i] = Image.open('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/' + test_image_names[i])\n",
    "\n",
    "    orig_w, orig_h = images[i].size\n",
    "\n",
    "\n",
    "    predictions[i]['boxes'] = predictions[i]['boxes'] * torch.tensor([orig_w/tran_w, \n",
    "                                                                      orig_h/tran_h, \n",
    "                                                                      orig_w/tran_w,\n",
    "                                                                      orig_h/tran_h]).view(1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**Plot Model Predictions for Images in Test Dataset**</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    \n",
    "    # add label and score to the bounding box. concatenate label and score to one string. \n",
    "    # use label_dict to replace class numbers with class names\n",
    "    ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "        s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "        color = 'black',\n",
    "        fontsize = 6,\n",
    "        verticalalignment = 'top',\n",
    "        bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "    return ax\n",
    "\n",
    "\n",
    "# function for plotting all predictions on images\n",
    "def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "    ax = img_show(image, ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 32 samples from batch in a grid of subplots.\n",
    "plt.figure(figsize = (24, 36))\n",
    "for i in range(0, 32):\n",
    "    ax = plt.subplot(8, 4, 1 + i)\n",
    "    plot_predictions(images[i], predictions[i]['boxes'], predictions[i]['labels'], predictions[i]['scores'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(test_image_names[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run inference on full dataset to get model estimates of abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all = MAVdroneDataset(csv_file = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_annotations.csv',\n",
    "                                root_dir = 'C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/filtered_images/', \n",
    "                                transforms = get_transform(train = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [dataset_all.unique_image_names[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of test indices and image names\n",
    "name_dict = dict(zip(indices, image_names))\n",
    "\n",
    "data_loader_all = torch.utils.data.DataLoader(dataset_all, batch_size = 1, shuffle = False,\n",
    "                                            collate_fn = utils.collate_fn, num_workers = 0,\n",
    "                                            pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model predictions for every image in data_loader_all\n",
    "model_predictions_all = []\n",
    "\n",
    "for images, targets in data_loader_all:\n",
    "    # use image_id to get image_name from image_names list\n",
    "    image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "    # convert boxes in targets to tensors\n",
    "    targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(images, targets)\n",
    "\n",
    "    # append image name to mean_AP\n",
    "    prediction['image_name'] = name_dict[image_id[0]]\n",
    "\n",
    "    # Append mean_AP and predictions to results list. \n",
    "    model_predictions_all.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "# results = []\n",
    "# metric = MeanAveragePrecision(iou_type=\"bbox\",\n",
    "#                               class_metrics=True,\n",
    "#                               max_detection_thresholds=[1, 10, 100]\n",
    "#                               )\n",
    "# model.to('cpu')\n",
    "# model.eval()\n",
    "\n",
    "# for images, targets in data_loader_all:\n",
    "#     # use image_id to get image_name from image_names list\n",
    "#     image_id = [target['image_id'].item() for target in targets]\n",
    "\n",
    "#     # convert boxes in targets to tensors\n",
    "#     targets = [{k: torch.tensor(v) if k == 'boxes' else v for k, v in t.items()} for t in targets]\n",
    "\n",
    "#     # filter targets to only include boxes and labels keys\n",
    "#     ground_truth = [{k: v for k, v in t.items() if k in ('boxes', 'labels')} for t in targets]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         prediction = model(images, targets)\n",
    "\n",
    "#     # calculate mAP and mAR from test dataset\n",
    "#     metric.update(prediction, ground_truth)\n",
    "#     mean_AP = metric.compute()\n",
    "\n",
    "#     # append image name to mean_AP\n",
    "#     mean_AP['image_name'] = name_dict[image_id[0]]\n",
    "\n",
    "#     # Append mean_AP and predictions to results list. \n",
    "#     results.append(mean_AP)\n",
    "\n",
    "# # use pandas to create a dataframe of image names and mAP values\n",
    "# results_df = pd.DataFrame()\n",
    "# results_df['image_name'] = [result['image_name'] for result in results]\n",
    "# results_df['mAP'] = [result['map'].item() for result in results]\n",
    "# results_df['mAP_50'] = [result['map_50'].item() for result in results]\n",
    "# results_df['mAP_75'] = [result['map_75'].item() for result in results]\n",
    "# results_df['mAP_small'] = [result['map_small'].item() for result in results]\n",
    "# results_df['mAP_medium'] = [result['map_medium'].item() for result in results]\n",
    "# results_df['mAP_large'] = [result['map_large'].item() for result in results]\n",
    "# results_df['mAR_1'] = [result['mar_1'].item() for result in results]\n",
    "# results_df['mAR_10'] = [result['mar_10'].item() for result in results]\n",
    "# results_df['mAR_100'] = [result['mar_100'].item() for result in results]\n",
    "# results_df['mAR_small'] = [result['mar_small'].item() for result in results]\n",
    "# results_df['mAR_medium'] = [result['mar_medium'].item() for result in results]\n",
    "# results_df['mAR_large'] = [result['mar_large'].item() for result in results]\n",
    "\n",
    "# # if value is == -1.0, replace with NaN\n",
    "# results_df = results_df.replace(-1.0, np.nan)\n",
    "\n",
    "# # save results_df to csv\n",
    "# results_df.to_csv('C:/Users/exx/Deep Learning/UAV_Waterfowl_Detection/all_image_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_res_df = pd.DataFrame()\n",
    "\n",
    "# # store 'map_per_class' and 'mar_100_per_class' from results in df\n",
    "# class_res_df['image_name'] = [result['image_name'] for result in results]\n",
    "# class_res_df['classes'] = [result['classes'] for result in results]\n",
    "# class_res_df['map_per_class'] = [result['map_per_class'] for result in results]\n",
    "# class_res_df['mar_100_per_class'] = [result['mar_100_per_class'] for result in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bohb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
