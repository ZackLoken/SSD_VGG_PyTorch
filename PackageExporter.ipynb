{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.0.1\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp39-cp39-win_amd64.whl (2619.2 MB)\n",
      "Collecting torchvision==0.15.2\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp39-cp39-win_amd64.whl (4.9 MB)\n",
      "Collecting torchaudio==2.0.2\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting filelock (from torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zack\\anaconda3\\envs\\ducknetexport\\lib\\site-packages (from torch==2.0.1) (4.9.0)\n",
      "Collecting sympy (from torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.7 MB 3.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.4/5.7 MB 5.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.0/5.7 MB 7.9 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.2/5.7 MB 9.4 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.2/5.7 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.0/5.7 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 3.5/5.7 MB 12.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.5/5.7 MB 13.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 14.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.7/5.7 MB 13.6 MB/s eta 0:00:00\n",
      "Collecting networkx (from torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 0.7/1.6 MB 22.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.6 MB 20.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 17.4 MB/s eta 0:00:00\n",
      "Collecting jinja2 (from torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 133.1/133.1 kB ? eta 0:00:00\n",
      "Collecting numpy (from torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.24.1-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.9/14.9 MB 30.1 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 2.0/14.9 MB 26.1 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 3.0/14.9 MB 24.0 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.6/14.9 MB 20.6 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.7/14.9 MB 21.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.8/14.9 MB 21.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.8/14.9 MB 21.6 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.8/14.9 MB 21.7 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.4/14.9 MB 20.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.6/14.9 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 10.8/14.9 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 12.0/14.9 MB 21.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 13.1/14.9 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.2/14.9 MB 22.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.9/14.9 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting requests (from torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 1.0/2.6 MB 31.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.2/2.6 MB 28.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 23.7 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Collecting charset-normalizer<3,>=2 (from requests->torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 0.0/61.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "     ---------------------------------------- 0.0/140.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 140.6/140.6 kB ? eta 0:00:00\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.2)\n",
      "  Downloading https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "     ---------------------------------------- 0.0/155.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 155.3/155.3 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.0.1)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 536.2/536.2 kB 11.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, urllib3, sympy, pillow, numpy, networkx, MarkupSafe, idna, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 certifi-2022.12.7 charset-normalizer-2.1.1 filelock-3.9.0 idna-3.4 jinja2-3.1.2 mpmath-1.3.0 networkx-3.2.1 numpy-1.24.1 pillow-10.2.0 requests-2.28.1 sympy-1.12 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 urllib3-1.26.13\n"
     ]
    }
   ],
   "source": [
    "! pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as T\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "\n",
    "model = torchvision.models.detection.ssd300_vgg16()\n",
    "model.load_state_dict(torch.load('C:/Users/zack/Documents/GitHub/SSD_VGG_PyTorch/ssd300_vgg16_gradientAccumulation_noHen.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {4.0: 'MALL', 1.0: 'AMCO', 3.0: 'GWTE', 6.0: 'NSHO', 2.0: 'GADW', 8.0: 'RNDU', 5.0: 'NOPI', 7.0: 'REDH'}\n",
    "\n",
    "# distinct colors \n",
    "distinct_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    "\n",
    "def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    \n",
    "    # add label and score to the bounding box. concatenate label and score to one string. \n",
    "    # use label_dict to replace class numbers with class names\n",
    "    ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "        s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "        color = 'black',\n",
    "        fontsize = 6,\n",
    "        verticalalignment = 'top',\n",
    "        bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "    return ax\n",
    "\n",
    "\n",
    "# function for plotting all predictions on images\n",
    "def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "    ax = img_show(image, ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'E:/Zack/Research/Object Detection/Duck_Drone_Detection_Data/filtered_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, dir):\n",
    "    # set model to evaluation\n",
    "    model.eval()\n",
    "    # get image\n",
    "    image_files = os.listdir(dir)\n",
    "    for i in range(8):\n",
    "        image = PIL.Image.open(os.path.join(dir, image_files[i]))\n",
    "        \n",
    "        width, height = image.size\n",
    "\n",
    "        # convert image to tensor\n",
    "        image_tensor = T.ToImageTensor()(image)\n",
    "\n",
    "        # # add batch dimension\n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "        image_tensor = image_tensor.to(torch.float32)\n",
    "\n",
    "        # resize to 300x300\n",
    "        image_tensor = T.Resize((300, 300), antialias=True)(image_tensor)\n",
    "\n",
    "        # normalize image\n",
    "        image_tensor = T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])(image_tensor)\n",
    "        \n",
    "        # run model\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "\n",
    "        # get boxes, labels, and scores\n",
    "        boxes = output[0]['boxes']\n",
    "        labels = output[0]['labels']\n",
    "        scores = output[0]['scores']\n",
    "\n",
    "        # filter out boxes with scores less than 0.5\n",
    "        boxes = boxes[scores > 0.5]\n",
    "        labels = labels[scores > 0.5]\n",
    "        scores = scores[scores > 0.5]\n",
    "\n",
    "        # rescale boxes to original image size\n",
    "        boxes[:, 0] *= width / 300\n",
    "        boxes[:, 1] *= height / 300\n",
    "        boxes[:, 2] *= width / 300\n",
    "        boxes[:, 3] *= height / 300\n",
    "\n",
    "        # plot predictions\n",
    "        plot_predictions(image, boxes, labels, scores)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(model, dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import package\n",
    "\n",
    "path = \"model.pt\"\n",
    "package_name = \"DuckNet\"\n",
    "resource_name = \"model.pkl\"\n",
    "\n",
    "with package.PackageExporter(path, debug=True) as exp:\n",
    "    exp.intern(\"torchvision.**\")\n",
    "    exp.extern(\"pycocotools.**\")\n",
    "    exp.extern(\"PIL.**\")\n",
    "    exp.extern(\"io\")\n",
    "    exp.extern(\"matplotlib.**\")\n",
    "    exp.extern(\"sys\")\n",
    "    exp.extern(\"requests\")\n",
    "    exp.extern(\"numpy\")\n",
    "    exp.extern(\"scipy.**\")\n",
    "    exp.extern(\"h5py\")\n",
    "    exp.extern(\"__future__\")\n",
    "    exp.save_pickle(package_name, resource_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = package.PackageImporter(path)\n",
    "loaded_model = imp.load_pickle(package_name, resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(loaded_model, dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSD_PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
